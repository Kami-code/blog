<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>(CVPR2020)GraspNet-1Billion - Ryan &#039;s website</title><link rel="manifest" href="/blog/manifest.json"><meta name="application-name" content="Ryan&#039;s blog"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Ryan&#039;s blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="​    最近在研究各种各样的GraspNet，组内浩树学长的GraspNet虽然我已经用了很久，但是在方法论和具体实现上一直没有时间去研究，借着寒假的机会来集中学习一下。"><meta property="og:type" content="blog"><meta property="og:title" content="(CVPR2020)GraspNet-1Billion"><meta property="og:url" content="https://kami-code.com/blog/2022/01/18/GraspNet-1Billion/"><meta property="og:site_name" content="Ryan &#039;s website"><meta property="og:description" content="​    最近在研究各种各样的GraspNet，组内浩树学长的GraspNet虽然我已经用了很久，但是在方法论和具体实现上一直没有时间去研究，借着寒假的机会来集中学习一下。"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://kami-code.com/blog/blog/2022/01/18/GraspNet-1Billion/image-20220118155632080.png"><meta property="article:published_time" content="2022-01-18T06:33:35.000Z"><meta property="article:modified_time" content="2022-02-13T06:22:43.123Z"><meta property="article:author" content="Kami-code"><meta property="article:tag" content="GraspNet"><meta property="article:tag" content="CVPR"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/blog/blog/2022/01/18/GraspNet-1Billion/image-20220118155632080.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://kami-code.com/blog/2022/01/18/GraspNet-1Billion/"},"headline":"(CVPR2020)GraspNet-1Billion","image":["https://kami-code.com/blog/blog/2022/01/18/GraspNet-1Billion/image-20220118155632080.png"],"datePublished":"2022-01-18T06:33:35.000Z","dateModified":"2022-02-13T06:22:43.123Z","author":{"@type":"Person","name":"Kami-code"},"publisher":{"@type":"Organization","name":"Ryan 's website","logo":{"@type":"ImageObject","url":"https://kami-code.com/img/logo.svg"}},"description":"​    最近在研究各种各样的GraspNet，组内浩树学长的GraspNet虽然我已经用了很久，但是在方法论和具体实现上一直没有时间去研究，借着寒假的机会来集中学习一下。"}</script><link rel="canonical" href="https://kami-code.com/blog/2022/01/18/GraspNet-1Billion/"><link rel="icon" href="/blog/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/blog/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/blog/"><img src="/blog/img/logo.svg" alt="Ryan &#039;s website" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/blog/">Home</a><a class="navbar-item" href="/blog/archives">Archives</a><a class="navbar-item" href="/blog/categories">Categories</a><a class="navbar-item" href="/blog/tags">Tags</a><a class="navbar-item" href="/blog/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-01-18T06:33:35.000Z" title="2022/1/18 下午2:33:35">2022-01-18</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-02-13T06:22:43.123Z" title="2022/2/13 下午2:22:43">2022-02-13</time></span><span class="level-item">an hour read (About 11783 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">(CVPR2020)GraspNet-1Billion</h1><div class="content"><p>​    最近在研究各种各样的GraspNet，组内浩树学长的<a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Fang_GraspNet-1Billion_A_Large-Scale_Benchmark_for_General_Object_Grasping_CVPR_2020_paper.pdf">GraspNet</a>虽然我已经用了很久，但是在方法论和具体实现上一直没有时间去研究，借着寒假的机会来集中学习一下。</p>
<span id="more"></span>

<p>​    其实GraspNet-1Billion包含三部分，大规模的数据集、网络和benchmark。</p>
<h1 id="数据集部分"><a href="#数据集部分" class="headerlink" title="数据集部分"></a>数据集部分</h1><p>​    数据集包含88个日常常见的物体的3D模型。数据是从190个clutter scene中收集的，每个scene中，2个深度摄像机拍512张深度图，共97280张图片。每张图片中，我们通过计算force closure的方法稠密标注了6D grasp pose。每个场景中通常会有300万到900万个Grasp Pose。</p>
<h2 id="数据收集"><a href="#数据收集" class="headerlink" title="数据收集"></a>数据收集</h2><p>​    我原以为是仿真器里渲染的，居然真的是在现实世界中采集的，这样的话就不存在什么sim2real的问题了。两个深度相机同时拍摄场景并且合成成一个点云。摄像机所固连的机械臂的末端执行器在单位球面上找到了256个位置拍摄。地面上还放置了ArUco marker来协助摄像机标定，这样避免了计算fk所带来的误差。</p>
<h2 id="数据标定"><a href="#数据标定" class="headerlink" title="数据标定"></a>数据标定</h2><p>​    有了这97280张图以后，因为每256个位置的相对位置都是已知的，所以我们只需要标定每个的第一帧即可，即380张。但是Grasp Pose分布在一个大型的连续搜索空间中，是标不完的，手动标是巨大的工作量。因为我们的每个物体是已知的，文章中提出了一个2阶段的Grasp Pose标注方法。</p>
<p>​    首先，我们在单个物体上采样并标注Grasp Pose。为了达到这个目的，我们先把单个物体的网格模型降采样成均匀分布的Voxel space，其中的每个点称为grasp point。对于每个Grasp Point，我们从单位球找到V个均匀分布的approaching vector。然后，我们在二维网格$D\times A$上搜索（其中D是夹爪深度，而A是in-plane旋转角度）。</p>
<p>​    我们使用理论计算的方法来对每个Grasp打分，force-closure指标是很有用的：给定一个Grasp Pose、相关的Object以及摩擦系数$\mu$，它可以输出一个二分类的标签来判断这个Grasp是否可以在对应的摩擦系数下被抓起来。因为force-closure是基于物理的，所以比较鲁棒。此处我们采用<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1809.06267">24</a>所提到的一个改进版本，使用$\Delta\mu=0.1$作为间隔，我们逐渐从1递减到0.1，直到Grasp不再antipodal。因为具有更低摩擦系数$\mu$的成功抓取更容易成功，所以我们定义Grasp的成功率为：$s=1.1-\mu$。</p>
<p>​    对于每个scene，我们把对应单个物体的Grasp投影到clutter的场景中，此外还做了collision-check来避免非法的情况。在这两部以后，我们就对每个scene创建了稠密的抓取集合$G_{(w)}$。根据统计，数据集中正例和反例的比例为1:2。</p>
<h2 id="数据集评估"><a href="#数据集评估" class="headerlink" title="数据集评估"></a>数据集评估</h2><p>​    对于190个场景，100个用来训练、90个用来测试。我们进一步把测试集分类为3种： 30 scenes with seen objects, 30 with unseen but similar objects and 30 for novel objects。</p>
<p>​    为了评估Grasp Pose的预测表现，之前的方法通常认为一个正确的Grasp需要满足：</p>
<ul>
<li><p>rotation error小于$30^{\circ}$</p>
</li>
<li><p>矩形的IOU（Intersection over Union）大于0.25</p>
</li>
</ul>
<p>​    但是这样的度量指标有一些问题，比如它只能评估Grasp Pose的矩阵表示方法，并且它的错误容忍度太高了，康奈尔数据集已经可以达到99%的进度了。这篇工作提出了一个在线的评估算法来评估Grasp的精度。</p>
<p>​    我们首先演示如何来分类是否一个Grasp Pose是true positive的。对于每个预测出来的Grasp Pose$\hat{P}_i$，我们首先做collision-checking，第二部就是我们通过force-closure来判断在给定不同的摩擦系数$\mu$下是否可以抓取。</p>
<p>​    对于cluttered scene，我们的Grasp预测算法会预测出多个Grasp Pose。因为对于抓取来说，我们通常是预测以后再执行的，所以我们认为true positive的比例是最重要的。因此，我们采用Precision@k作为我们的评估指标，也就是前k个抓取的精度。$AP_\mu$在摩擦系数$\mu$代表Precision@k的均值（k从1取到50）。和COCO数据集类似，我们在不同的摩擦系数$\mu$来计算$AP_\mu$。为了避免相同的Grasp Pose，在评估之前，我们对Grasp Pose来使用pose-NMS。</p>
<p><img src="/blog/blog/2022/01/18/GraspNet-1Billion/image-20220118155632080.png"></p>
<p>​        网络结构整体上我觉得和VoteNet非常接近，也是生成M个seeds。然后通过ApproachNet把Grasp的接近向量做一个多分类出来。然后我们对这M个grasp proposal做KNN聚类，聚出来K个grasp proposal。对于每个接近向量，我们继续做多分类，在$D\times A$上找到一个分数最大的夹爪渐进距离和角度。</p>
<h2 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h2><p>​    对于每个候选点，我们为它分配一个二分类标签来表示它是否是可以抓取的。</p>
<ul>
<li>对于那些不在物体上的点，我们直接认为是失败的样本。</li>
<li>对于在物体上的点，我们在5mm半径内寻找它是否存在至少一个graspable的GT。如果存在，对应的graspable标签即为1。</li>
<li>如果物体上的点附近5mm半径内没有graspable的GT，那么我们忽略掉这种情况，因为对我们的训练没有贡献。</li>
</ul>
<p>​    对于每个点，我们有V个approaching vector，我们定义第i个点的第j个approaching vector为$v_{ij}$。我们然后寻找它对应的GT向量：$\hat{v}_{ij}$。类似地，我们只考虑相差在5度以内的。最终，我们的损失函数定义如下：<br>$$<br>L^A({c_i},{s_{ij}})=\frac{1}{N_{cls}}\sum_iL_{cls}(c_i,c_i^*)+\lambda_1\frac{1}{N_{reg}}\sum_i\sum_j c_i^*<br>\mathbf{1}(|v_{ij},v_{ij}^*|&lt;5^{\circ})L_{reg}(s_{ij},s_{ij}^*))<br>$$<br>​    其中$s_{ij}$代表网络预测的第i个点的confidence score。而$s_{ij}^*$是对应的GT，是通过EQ2选出来的最大的grasp的置信度。$|v_{ij},v^*_{ij}|$代表的就是角度差。指示函数$\mathbf{1}()$约束了一个approaching vector所产生的loss是通过它附近5度内的GT所提供的。    </p>
<p>​    这个损失函数前半部分就是说，希望对每个点可以正确地二分类到graspable还是not graspable。后半部分就是说，对于每个graspable的点（满足$c_i^*==1$），它存在V个approaching vector，我们希望通过稠密的Grasp GT来让每个approaching vector都能预测出一个confidence score，也就是对应Grasp数据集创建时候，所计算出来的成功率。</p>
<h2 id="Operation-Network"><a href="#Operation-Network" class="headerlink" title="Operation Network"></a>Operation Network</h2><p>​    在得到了graspable points的approaching vector之后，我们需要进一步预测in-plane rotation, approaching distance, gripper width和grasp confidence。</p>
<h3 id="Cylinder-Region-Transformation"><a href="#Cylinder-Region-Transformation" class="headerlink" title="Cylinder Region Transformation"></a>Cylinder Region Transformation</h3><p>​    文章提出了一个统一的Grasp表示方式。因为approaching distance相对不那么敏感，所以分为了K个bin，对于每个给定的distance $d_k$，我们在圆柱中沿着approaching vector采样一些点。这些采样的点会转化到一个新的坐标系下，其原点是Grasp point，而z轴就是approaching vector $v_{ij}$。</p>
<h3 id="Rotation和Width"><a href="#Rotation和Width" class="headerlink" title="Rotation和Width"></a>Rotation和Width</h3><p>​    在之前的文章中，证明了预测in-plane rotation时，分类比起回归有更好的效果。所以，rotation network把对齐过的点云作为输入，输出分类的分数、对每个rotation bin的归一化过的残差，以及对应的grasp width和grasp confidence。因为夹爪是对称的，所以我们只需要预测0~180度即可。目标函数如下：<br>$$<br>L^R(R_{ij},S_{ij},{W_{ij}})=\sum_{d=1}^K\left(\frac{1}{N_{cls}}\sum_{ij}L^d_{cls}(R_{ij},R_{ij}^*)+\lambda_2\frac{1}{N_{reg}}\sum_{ij}L^d_{reg}(S_{ij},S^*_{ij})+\lambda_3\frac{1}{N_{reg}}\sum_{ij}L^d_{reg}(W_{ij}, W^*_{ij})\right)<br>$$<br>​    其中$R_{ij}$代表binned rotation degree, $S_{ij}$代表grasp confidence score，$W_{ij}$代表夹爪闭合宽度，$d$代表approaching distance。其中$L^d$代表的是第d个binned distance的loss。此处的$L_{cls}$代表的是多分类任务的交叉熵损失。</p>
<h3 id="Tolerance-Network"><a href="#Tolerance-Network" class="headerlink" title="Tolerance Network"></a>Tolerance Network</h3><p>​    现在我们已经有了一个end-to-end的网络了。本文进一步提出了Grasp Affinity Field（GAFs）的概念，它可以提升预测出来的Grasp的鲁棒性。因为合法的Grasp Pose是无限的，我们希望能够挑选出那些可以容忍更大error的鲁棒的Grasp。所以，GAFs就学习的是每个grasp对于扰动的鲁棒性。</p>
<p>​    给定一个GT的grasp pose，我们在球空间中搜索它的邻域，来找到满足grasp score &gt; 0.5的最远的距离作为GATs。损失函数如下：<br>$$<br>L^F(A_{ij})=\frac{1}{N_{reg}}\sum_{d=1}^K\sum_{ij}L^d_{reg}(T_{ij},T_{ij}^*)<br>$$<br>​    其中$T_{ij}$代表了grasp pose可以忍受的最大的扰动。</p>
<p>​    在训练过程中，网络的总的目标函数如下<br>$$<br>L=L^A({c_i},{s_{ij}})+\alpha L^R(R_{ij}, S_{ij}, W_{ij})+\beta L^F(T_{ij})<br>$$<br>​    在推理阶段，我们把grasp根据分数分成10个bin，然后在每个bin中根据tolerance network的计算出来的扰动程度来排序。</p>
<h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><h3 id="GT-Evaluation"><a href="#GT-Evaluation" class="headerlink" title="GT Evaluation"></a>GT Evaluation</h3><p>​    为了评估预测的Grasp Pose，本文设立了一个真机实验，因为在现实中需要获取到物体的6D Pose才能做投影，把ArUco code贴在物体上。</p>
<p>​    </p>
<p>​    对于训练过程，我们把in-plane rotational angle分成了12个bin、approaching distance分成了4个bin(0.01, 0.02, 0.03, 0.04)m。我们设置$M=1024$和$V=300$。我们的ApproachNet有MLP(256, 302, 302)，OperationNet有MLP(128, 128, 36)和ToleranceNet有MLP(128, 64, 12)。</p>
<h1 id="具体代码实现"><a href="#具体代码实现" class="headerlink" title="具体代码实现"></a>具体代码实现</h1><h2 id="数据集格式"><a href="#数据集格式" class="headerlink" title="数据集格式"></a>数据集格式</h2><p>​        数据集的官网说明如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">1. Download, unzip all the files and place them in the following structure, </span><br><span class="line">   the train images and test images contain the 190 scenes in total.</span><br><span class="line">|-- graspnet</span><br><span class="line">    |-- scenes</span><br><span class="line">    |   |-- scene_0000/</span><br><span class="line">    |   |-- scene_0001/</span><br><span class="line">    |   |-- ... ...</span><br><span class="line">    |   `-- scene_0189/</span><br><span class="line">    |</span><br><span class="line">    |</span><br><span class="line">    |-- models</span><br><span class="line">    |   |-- 000/</span><br><span class="line">    |   |-- 001/</span><br><span class="line">    |   |-- ...</span><br><span class="line">    |   `-- 087/</span><br><span class="line">    |</span><br><span class="line">    |</span><br><span class="line">    |-- dex_models(optional but strongly recommended for accelerating evaluation)</span><br><span class="line">    |   |-- 000.pkl</span><br><span class="line">    |   |-- 001.pkl</span><br><span class="line">    |   |-- ...</span><br><span class="line">    |   `-- 087.pkl</span><br><span class="line">    |   </span><br><span class="line">    |</span><br><span class="line">    |-- grasp_label</span><br><span class="line">    |   |-- 000_labels.npz</span><br><span class="line">    |   |-- 001_labels.npz</span><br><span class="line">    |   |-- ...</span><br><span class="line">    |   `-- 087_labels.npz</span><br><span class="line">    |</span><br><span class="line">    |</span><br><span class="line">    `-- collision_label</span><br><span class="line">        |-- scene_0000/</span><br><span class="line">        |-- scene_0001/</span><br><span class="line">        |-- ... ...</span><br><span class="line">        `-- scene_0189/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">2. Detail structure of each scene</span><br><span class="line">|-- scenes</span><br><span class="line">    |-- scene_0000</span><br><span class="line">    |   |-- object_id_list.txt              # objects&#x27; id that appear in this scene, 0-indexed</span><br><span class="line">    |   |-- rs_wrt_kn.npy                   # realsense camera pose with respect to kinect, shape: 256x(4x4)</span><br><span class="line">    |   |-- kinect                          # data of kinect camera</span><br><span class="line">    |   |   |-- rgb                         </span><br><span class="line">    |   |   |   |-- 0000.png to 0255.png    # 256 rgb images</span><br><span class="line">    |   |   `-- depth</span><br><span class="line">    |   |   |   |-- 0000.png to 0255.png    # 256 depth images</span><br><span class="line">    |   |   `-- label</span><br><span class="line">    |   |   |   |-- 0000.png to 0255.png    # 256 object mask images, 0 is background, 1-88 denotes each object (1-indexed), same format as YCB-Video dataset</span><br><span class="line">    |   |   `-- annotations</span><br><span class="line">    |   |   |   |-- 0000.xml to 0255.xml    # 256 object 6d pose annotation. ‘pos_in_world&#x27; and&#x27;ori_in_world&#x27; denotes position and orientation w.r.t the camera frame. </span><br><span class="line">    |   |   `-- meta</span><br><span class="line">    |   |   |   |-- 0000.mat to 0255.mat    # 256 object 6d pose annotation, same format as YCB-Video dataset for easy usage</span><br><span class="line">    |   |   `-- rect</span><br><span class="line">    |   |   |   |-- 0000.npy to 0255.npy    # 256 2D planar grasp labels</span><br><span class="line">    |   |   |   </span><br><span class="line">    |   |   `-- camK.npy                    # camera intrinsic, shape: 3x3, [[f_x,0,c_x], [0,f_y,c_y], [0,0,1]]</span><br><span class="line">    |   |   `-- camera_poses.npy            # 256 camera poses with respect to the first frame, shape: 256x(4x4)</span><br><span class="line">    |   |   `-- cam0_wrt_table.npy          # first frame&#x27;s camera pose with respect to the table, shape: 4x4</span><br><span class="line">    |   |</span><br><span class="line">    |   `-- realsense</span><br><span class="line">    |       |-- same structure as kinect</span><br><span class="line">    |</span><br><span class="line">    |</span><br><span class="line">    `-- scene_0001</span><br><span class="line">    |</span><br><span class="line">    `-- ... ...</span><br><span class="line">    |</span><br><span class="line">    `-- scene_0189</span><br></pre></td></tr></table></figure>

<p>​    我们可以看到190个场景，每个都有对应的256张RGB, depth，mask，以及每个场景中10个物体的id、Pose、以及两个摄像机的外参矩阵。</p>
<p>​    而Grasp Label的格式可以通过<a target="_blank" rel="noopener" href="https://graspnetapi.readthedocs.io/en/latest/grasp_format.html">API官网</a>找到，注意到是88种物体，每一个都有一组Grasp Label。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>l = np.load(<span class="string">&#x27;000_labels.npz&#x27;</span>) <span class="comment"># GRASPNET_ROOT/grasp_label/000_labels.npz</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>l.files</span><br><span class="line">[<span class="string">&#x27;points&#x27;</span>, <span class="string">&#x27;offsets&#x27;</span>, <span class="string">&#x27;collision&#x27;</span>, <span class="string">&#x27;scores&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>l[<span class="string">&#x27;points&#x27;</span>].shape</span><br><span class="line">(<span class="number">3459</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>l[<span class="string">&#x27;offsets&#x27;</span>].shape</span><br><span class="line">(<span class="number">3459</span>, <span class="number">300</span>, <span class="number">12</span>, <span class="number">4</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>l[<span class="string">&#x27;collision&#x27;</span>].shape</span><br><span class="line">(<span class="number">3459</span>, <span class="number">300</span>, <span class="number">12</span>, <span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>l[<span class="string">&#x27;collision&#x27;</span>].dtype</span><br><span class="line">dtype(<span class="string">&#x27;bool&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>l[<span class="string">&#x27;scores&#x27;</span>].shape</span><br><span class="line">(<span class="number">3459</span>, <span class="number">300</span>, <span class="number">12</span>, <span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>l[<span class="string">&#x27;scores&#x27;</span>][<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">-<span class="number">1.0</span></span><br></pre></td></tr></table></figure>

<ul>
<li>[‘points’] 记录了模型坐标系下的Grasp Center Point。</li>
<li>[‘offsets’] 记录了对应Grasp的in-plane rotation，夹爪深度和夹爪宽度。</li>
<li>[‘collision’] 记录了对应Grasp是否和物体模型存在碰撞。</li>
<li>[‘scores’] 记录了达到稳定Grasp时最小的摩擦系数。 </li>
</ul>
<p>​    还有一个比较重要的数据就是每个场景的collision_label，在官网中也被成为<a target="_blank" rel="noopener" href="https://graspnetapi.readthedocs.io/en/latest/grasp_format.html#collision-masks-on-each-scene">Collision Masks on Each Scene</a>。具体地，因为我们每个场景中维护了物体的6D Pose，我们是知道每个Grasp的位置在哪里的，我们可以预先地把我们的夹爪模型放上去做碰撞检测。如果Gripper和场景中的Model有碰撞，对于的collision_label就设置为True，我们要在训练的时候把存在碰撞的Grasp Pose的score设置为0。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = np.load(<span class="string">&#x27;collision_labels.npz&#x27;</span>) <span class="comment"># GRASPNET_ROOT/collision_label/scene_0000/collision_labels.npz</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c.files</span><br><span class="line">[<span class="string">&#x27;arr_0&#x27;</span>, <span class="string">&#x27;arr_4&#x27;</span>, <span class="string">&#x27;arr_5&#x27;</span>, <span class="string">&#x27;arr_2&#x27;</span>, <span class="string">&#x27;arr_3&#x27;</span>, <span class="string">&#x27;arr_7&#x27;</span>, <span class="string">&#x27;arr_1&#x27;</span>, <span class="string">&#x27;arr_8&#x27;</span>, <span class="string">&#x27;arr_6&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c[<span class="string">&#x27;arr_0&#x27;</span>].shape</span><br><span class="line">(<span class="number">487</span>, <span class="number">300</span>, <span class="number">12</span>, <span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c[<span class="string">&#x27;arr_0&#x27;</span>].dtype</span><br><span class="line">dtype(<span class="string">&#x27;bool&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c[<span class="string">&#x27;arr_0&#x27;</span>][<span class="number">10</span>][<span class="number">20</span>][<span class="number">3</span>]</span><br><span class="line">array([ <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>])</span><br></pre></td></tr></table></figure>

<h2 id="DataLoader"><a href="#DataLoader" class="headerlink" title="DataLoader"></a>DataLoader</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GraspNetDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, root, valid_obj_idxs, grasp_labels, camera=<span class="string">&#x27;kinect&#x27;</span>, split=<span class="string">&#x27;train&#x27;</span>, num_points=<span class="number">20000</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 remove_outlier=<span class="literal">False</span>, remove_invisible=<span class="literal">True</span>, augment=<span class="literal">False</span>, load_label=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="keyword">assert</span>(num_points&lt;=<span class="number">50000</span>)</span><br><span class="line">		<span class="comment"># ignore some self.x = x</span></span><br><span class="line">        <span class="keyword">if</span> split == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">            self.sceneIds = <span class="built_in">list</span>( <span class="built_in">range</span>(<span class="number">100</span>) )</span><br><span class="line">        <span class="keyword">elif</span> split == <span class="string">&#x27;test&#x27;</span>:</span><br><span class="line">            self.sceneIds = <span class="built_in">list</span>( <span class="built_in">range</span>(<span class="number">100</span>,<span class="number">190</span>) )</span><br><span class="line">        <span class="keyword">elif</span> split == <span class="string">&#x27;test_seen&#x27;</span>:</span><br><span class="line">            self.sceneIds = <span class="built_in">list</span>( <span class="built_in">range</span>(<span class="number">100</span>,<span class="number">130</span>) )</span><br><span class="line">        <span class="keyword">elif</span> split == <span class="string">&#x27;test_similar&#x27;</span>:</span><br><span class="line">            self.sceneIds = <span class="built_in">list</span>( <span class="built_in">range</span>(<span class="number">130</span>,<span class="number">160</span>) )</span><br><span class="line">        <span class="keyword">elif</span> split == <span class="string">&#x27;test_novel&#x27;</span>:</span><br><span class="line">            self.sceneIds = <span class="built_in">list</span>( <span class="built_in">range</span>(<span class="number">160</span>,<span class="number">190</span>) )</span><br><span class="line">        self.sceneIds = [<span class="string">&#x27;scene_&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">str</span>(x).zfill(<span class="number">4</span>)) <span class="keyword">for</span> x <span class="keyword">in</span> self.sceneIds]</span><br><span class="line">        <span class="comment"># ignore some dir concat</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">scene_list</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.scenename</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.depthpath)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.load_label:</span><br><span class="line">            <span class="keyword">return</span> self.get_data_label(index)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.get_data(index)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_data</span>(<span class="params">self, index, return_raw_cloud=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="comment"># 仅读入depth, pointcloud, mask，不读入grasp_label，</span></span><br><span class="line">        color = np.array(Image.<span class="built_in">open</span>(self.colorpath[index]), dtype=np.float32) / <span class="number">255.0</span></span><br><span class="line">        depth = np.array(Image.<span class="built_in">open</span>(self.depthpath[index]))</span><br><span class="line">        seg = np.array(Image.<span class="built_in">open</span>(self.labelpath[index]))</span><br><span class="line">        meta = scio.loadmat(self.metapath[index])</span><br><span class="line">        scene = self.scenename[index]</span><br><span class="line">        intrinsic = meta[<span class="string">&#x27;intrinsic_matrix&#x27;</span>]</span><br><span class="line">        factor_depth = meta[<span class="string">&#x27;factor_depth&#x27;</span>]</span><br><span class="line">        camera = CameraInfo(<span class="number">1280.0</span>, <span class="number">720.0</span>, intrinsic[<span class="number">0</span>][<span class="number">0</span>], intrinsic[<span class="number">1</span>][<span class="number">1</span>], intrinsic[<span class="number">0</span>][<span class="number">2</span>], intrinsic[<span class="number">1</span>][<span class="number">2</span>], factor_depth)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 合成点云</span></span><br><span class="line">        cloud = create_point_cloud_from_depth_image(depth, camera, organized=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 得到两个mask</span></span><br><span class="line">        depth_mask = (depth &gt; <span class="number">0</span>)</span><br><span class="line">        seg_mask = (seg &gt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">if</span> self.remove_outlier:</span><br><span class="line">            camera_poses = np.load(os.path.join(self.root, <span class="string">&#x27;scenes&#x27;</span>, scene, self.camera, <span class="string">&#x27;camera_poses.npy&#x27;</span>))</span><br><span class="line">            align_mat = np.load(os.path.join(self.root, <span class="string">&#x27;scenes&#x27;</span>, scene, self.camera, <span class="string">&#x27;cam0_wrt_table.npy&#x27;</span>))</span><br><span class="line">            trans = np.dot(align_mat, camera_poses[self.frameid[index]])</span><br><span class="line">            workspace_mask = get_workspace_mask(cloud, seg, trans=trans, organized=<span class="literal">True</span>, outlier=<span class="number">0.02</span>)</span><br><span class="line">            mask = (depth_mask &amp; workspace_mask)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mask = depth_mask</span><br><span class="line">        cloud_masked = cloud[mask]</span><br><span class="line">        color_masked = color[mask]</span><br><span class="line">        seg_masked = seg[mask]</span><br><span class="line">        <span class="keyword">if</span> return_raw_cloud:</span><br><span class="line">            <span class="keyword">return</span> cloud_masked, color_masked</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果点太多，那么就采样固定的点输出</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(cloud_masked) &gt;= self.num_points:</span><br><span class="line">            idxs = np.random.choice(<span class="built_in">len</span>(cloud_masked), self.num_points, replace=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            idxs1 = np.arange(<span class="built_in">len</span>(cloud_masked))</span><br><span class="line">            idxs2 = np.random.choice(<span class="built_in">len</span>(cloud_masked), self.num_points-<span class="built_in">len</span>(cloud_masked), replace=<span class="literal">True</span>)</span><br><span class="line">            idxs = np.concatenate([idxs1, idxs2], axis=<span class="number">0</span>)</span><br><span class="line">        cloud_sampled = cloud_masked[idxs]</span><br><span class="line">        color_sampled = color_masked[idxs]</span><br><span class="line">        </span><br><span class="line">        ret_dict = &#123;&#125;</span><br><span class="line">        ret_dict[<span class="string">&#x27;point_clouds&#x27;</span>] = cloud_sampled.astype(np.float32)</span><br><span class="line">        ret_dict[<span class="string">&#x27;cloud_colors&#x27;</span>] = color_sampled.astype(np.float32)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> ret_dict</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_data_label</span>(<span class="params">self, index</span>):</span></span><br><span class="line">		<span class="comment"># 省略了get_data的所有逻辑，基于get_data的函数之后，这个函数做了如下的处理</span></span><br><span class="line">        cloud_sampled = cloud_masked[idxs]</span><br><span class="line">        color_sampled = color_masked[idxs]</span><br><span class="line">        seg_sampled = seg_masked[idxs]</span><br><span class="line">        objectness_label = seg_sampled.copy()</span><br><span class="line">        objectness_label[objectness_label&gt;<span class="number">1</span>] = <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        object_poses_list = []</span><br><span class="line">        grasp_points_list = []</span><br><span class="line">        grasp_offsets_list = []</span><br><span class="line">        grasp_scores_list = []</span><br><span class="line">        grasp_tolerance_list = []</span><br><span class="line">        <span class="keyword">for</span> i, obj_idx <span class="keyword">in</span> <span class="built_in">enumerate</span>(obj_idxs):	<span class="comment"># 枚举场景中的10类物体</span></span><br><span class="line">            <span class="keyword">if</span> obj_idx <span class="keyword">not</span> <span class="keyword">in</span> self.valid_obj_idxs:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">if</span> (seg_sampled == obj_idx).<span class="built_in">sum</span>() &lt; <span class="number">50</span>:	<span class="comment"># 拍到的对应物体点云数量太少</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            object_poses_list.append(poses[:, :, i])	<span class="comment"># 加入到合法的object_poses_list中</span></span><br><span class="line">            points, offsets, scores, tolerance = self.grasp_labels[obj_idx]	<span class="comment"># 得到物体坐标系下创建的Grasp Pose</span></span><br><span class="line">            collision = self.collision_labels[scene][i] <span class="comment"># 得到场景中的点的collision mask(Np, V, A, D)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># remove invisible grasp points</span></span><br><span class="line">            <span class="keyword">if</span> self.remove_invisible:</span><br><span class="line">                visible_mask = remove_invisible_grasp_points(cloud_sampled[seg_sampled==obj_idx], points, poses[:,:,i], th=<span class="number">0.01</span>)</span><br><span class="line">                points = points[visible_mask]</span><br><span class="line">                offsets = offsets[visible_mask]</span><br><span class="line">                scores = scores[visible_mask]</span><br><span class="line">                tolerance = tolerance[visible_mask]</span><br><span class="line">                collision = collision[visible_mask]</span><br><span class="line"></span><br><span class="line">            idxs = np.random.choice(<span class="built_in">len</span>(points), <span class="built_in">min</span>(<span class="built_in">max</span>(<span class="built_in">int</span>(<span class="built_in">len</span>(points)/<span class="number">4</span>),<span class="number">300</span>),<span class="built_in">len</span>(points)), replace=<span class="literal">False</span>)</span><br><span class="line">            grasp_points_list.append(points[idxs])</span><br><span class="line">            grasp_offsets_list.append(offsets[idxs])</span><br><span class="line">            collision = collision[idxs].copy()</span><br><span class="line">            scores = scores[idxs].copy()</span><br><span class="line">            tolerance = tolerance[idxs].copy()</span><br><span class="line">            scores[collision] = <span class="number">0</span></span><br><span class="line">            tolerance[collision] = <span class="number">0</span>	<span class="comment"># 场景中存在collision的情况，我们设置Grasp分数为0</span></span><br><span class="line">            grasp_scores_list.append(scores)</span><br><span class="line">            grasp_tolerance_list.append(tolerance)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果设置了这个，每次__getitem__的时候得到的数据也会有不一样，会有轻微的扰动，但是这样就不需要在创建Label的时候就加随机，降低的数据集的大小和处理的复杂度</span></span><br><span class="line">        <span class="keyword">if</span> self.augment:</span><br><span class="line">            cloud_sampled, object_poses_list = self.augment_data(cloud_sampled, object_poses_list)</span><br><span class="line">        </span><br><span class="line">        ret_dict = &#123;&#125;</span><br><span class="line">        ret_dict[<span class="string">&#x27;point_clouds&#x27;</span>] = cloud_sampled.astype(np.float32)</span><br><span class="line">        ret_dict[<span class="string">&#x27;cloud_colors&#x27;</span>] = color_sampled.astype(np.float32)</span><br><span class="line">        ret_dict[<span class="string">&#x27;objectness_label&#x27;</span>] = objectness_label.astype(np.int64)</span><br><span class="line">        ret_dict[<span class="string">&#x27;object_poses_list&#x27;</span>] = object_poses_list</span><br><span class="line">        ret_dict[<span class="string">&#x27;grasp_points_list&#x27;</span>] = grasp_points_list</span><br><span class="line">        ret_dict[<span class="string">&#x27;grasp_offsets_list&#x27;</span>] = grasp_offsets_list</span><br><span class="line">        ret_dict[<span class="string">&#x27;grasp_labels_list&#x27;</span>] = grasp_scores_list</span><br><span class="line">        ret_dict[<span class="string">&#x27;grasp_tolerance_list&#x27;</span>] = grasp_tolerance_list</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> ret_dict</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">augment_data</span>(<span class="params">self, point_clouds, object_poses_list</span>):</span></span><br><span class="line">   <span class="comment"># Flipping along the YZ plane</span></span><br><span class="line">    <span class="keyword">if</span> np.random.random() &gt; <span class="number">0.5</span>:</span><br><span class="line">        flip_mat = np.array([[-<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                            [ <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">                            [ <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]])</span><br><span class="line">        point_clouds = transform_point_cloud(point_clouds, flip_mat, <span class="string">&#x27;3x3&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(object_poses_list)):</span><br><span class="line">            object_poses_list[i] = np.dot(flip_mat, object_poses_list[i]).astype(np.float32)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 沿着z轴旋转</span></span><br><span class="line">    rot_angle = (np.random.random()*np.pi/<span class="number">3</span>) - np.pi/<span class="number">6</span> <span class="comment"># -30 ~ +30 degree</span></span><br><span class="line">    c, s = np.cos(rot_angle), np.sin(rot_angle)</span><br><span class="line">    rot_mat = np.array([[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                        [<span class="number">0</span>, c,-s],</span><br><span class="line">                        [<span class="number">0</span>, s, c]])</span><br><span class="line">    point_clouds = transform_point_cloud(point_clouds, rot_mat, <span class="string">&#x27;3x3&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(object_poses_list)):</span><br><span class="line">        object_poses_list[i] = np.dot(rot_mat, object_poses_list[i]).astype(np.float32)</span><br><span class="line">    <span class="keyword">return</span> point_clouds, object_poses_list</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collate_fn</span>(<span class="params">batch</span>):</span></span><br><span class="line">    <span class="comment"># 在train.py创建DataLoader的时候会使用到这个函数。</span></span><br><span class="line">    <span class="comment"># collate_fn：如何取样本的，我们可以定义自己的函数来准确地实现想要的功能</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(batch[<span class="number">0</span>]).__module__ == <span class="string">&#x27;numpy&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> torch.stack([torch.from_numpy(b) <span class="keyword">for</span> b <span class="keyword">in</span> batch], <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(batch[<span class="number">0</span>], container_abcs.Mapping):</span><br><span class="line">        <span class="keyword">return</span> &#123;key:collate_fn([d[key] <span class="keyword">for</span> d <span class="keyword">in</span> batch]) <span class="keyword">for</span> key <span class="keyword">in</span> batch[<span class="number">0</span>]&#125;</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(batch[<span class="number">0</span>], container_abcs.<span class="type">Sequence</span>):</span><br><span class="line">        <span class="keyword">return</span> [[torch.from_numpy(sample) <span class="keyword">for</span> sample <span class="keyword">in</span> b] <span class="keyword">for</span> b <span class="keyword">in</span> batch]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">raise</span> TypeError(<span class="string">&quot;batch must contain tensors, dicts or lists; found &#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">type</span>(batch[<span class="number">0</span>])))</span><br></pre></td></tr></table></figure>



<h2 id="graspnet-py"><a href="#graspnet-py" class="headerlink" title="graspnet.py"></a>graspnet.py</h2><p>​    我们首先来看GraspNet这个类。我们可以看到，GraspNetStage1其实就是我们的PointNet++ backbone和ApproachNet部分。而GraspNetStage2主要是OperationNet和ToleranceNet部分。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GraspNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_feature_dim=<span class="number">0</span>, num_view=<span class="number">300</span>, num_angle=<span class="number">12</span>, num_depth=<span class="number">4</span>, cylinder_radius=<span class="number">0.05</span>, hmin=-<span class="number">0.02</span>, hmax_list=[<span class="number">0.01</span>,<span class="number">0.02</span>,<span class="number">0.03</span>,<span class="number">0.04</span>], is_training=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.is_training = is_training</span><br><span class="line">        self.view_estimator = GraspNetStage1(input_feature_dim, num_view)</span><br><span class="line">        self.grasp_generator = GraspNetStage2(num_angle, num_depth, cylinder_radius, hmin, hmax_list, is_training)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, end_points</span>):</span></span><br><span class="line">        end_points = self.view_estimator(end_points)</span><br><span class="line">        <span class="keyword">if</span> self.is_training:</span><br><span class="line">            end_points = process_grasp_labels(end_points)</span><br><span class="line">        end_points = self.grasp_generator(end_points)</span><br><span class="line">        <span class="keyword">return</span> end_points</span><br></pre></td></tr></table></figure>

<p>​    根据forward的顺序，我们先来看看GarspNetStage1的逻辑：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GraspNetStage1</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_feature_dim=<span class="number">0</span>, num_view=<span class="number">300</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.backbone = Pointnet2Backbone(input_feature_dim)</span><br><span class="line">        self.vpmodule = ApproachNet(num_view, <span class="number">256</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, end_points</span>):</span></span><br><span class="line">        pointcloud = end_points[<span class="string">&#x27;point_clouds&#x27;</span>]</span><br><span class="line">        seed_features, seed_xyz, end_points = self.backbone(pointcloud, end_points)</span><br><span class="line">        end_points = self.vpmodule(seed_xyz, seed_features, end_points)</span><br><span class="line">        <span class="keyword">return</span> end_points</span><br></pre></td></tr></table></figure>

<p>​    其实就是走了一个Pointnet2Backbone和ApproachNet，关于PointNet不再赘述。我们来看看ApproachNet</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ApproachNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_view, seed_feature_dim</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot; Approach vector estimation from seed point features.</span></span><br><span class="line"><span class="string">            Input:</span></span><br><span class="line"><span class="string">                num_view: [int]</span></span><br><span class="line"><span class="string">                    number of views generated from each each seed point</span></span><br><span class="line"><span class="string">                seed_feature_dim: [int]</span></span><br><span class="line"><span class="string">                    number of channels of seed point features</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.num_view = num_view</span><br><span class="line">        self.in_dim = seed_feature_dim</span><br><span class="line">        self.conv1 = nn.Conv1d(self.in_dim, self.in_dim, <span class="number">1</span>)</span><br><span class="line">        self.conv2 = nn.Conv1d(self.in_dim, <span class="number">2</span>+self.num_view, <span class="number">1</span>)</span><br><span class="line">        self.conv3 = nn.Conv1d(<span class="number">2</span>+self.num_view, <span class="number">2</span>+self.num_view, <span class="number">1</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm1d(self.in_dim)</span><br><span class="line">        self.bn2 = nn.BatchNorm1d(<span class="number">2</span>+self.num_view)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, seed_xyz, seed_features, end_points</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot; Forward pass.</span></span><br><span class="line"><span class="string">            Input:</span></span><br><span class="line"><span class="string">                seed_xyz: (B, Ns, 3), coordinates of seed points</span></span><br><span class="line"><span class="string">                seed_features: (batch_size,feature_dim,num_seed)</span></span><br><span class="line"><span class="string">                    features of seed points</span></span><br><span class="line"><span class="string">                end_points: [dict]</span></span><br><span class="line"><span class="string">            Output:</span></span><br><span class="line"><span class="string">                end_points: [dict]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        B, num_seed, _ = seed_xyz.size()</span><br><span class="line">        features = F.relu(self.bn1(self.conv1(seed_features)), inplace=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># (B, C, Ns)</span></span><br><span class="line">        features = F.relu(self.bn2(self.conv2(features)), inplace=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># (B, 2 + V, Ns)</span></span><br><span class="line">        features = self.conv3(features)</span><br><span class="line">        <span class="comment"># (B, 2 + V, Ns)</span></span><br><span class="line">        objectness_score = features[:, :<span class="number">2</span>, :] <span class="comment"># (B, 2, Ns)</span></span><br><span class="line">        view_score = features[:, <span class="number">2</span>:<span class="number">2</span>+self.num_view, :].transpose(<span class="number">1</span>,<span class="number">2</span>).contiguous() </span><br><span class="line">        <span class="comment"># (B, Ns, V)</span></span><br><span class="line">        end_points[<span class="string">&#x27;objectness_score&#x27;</span>] = objectness_score</span><br><span class="line">        end_points[<span class="string">&#x27;view_score&#x27;</span>] = view_score</span><br><span class="line">        <span class="comment"># 找到一个最大Grasp score的approach vector的编号</span></span><br><span class="line">        top_view_scores, top_view_inds = torch.<span class="built_in">max</span>(view_score, dim=<span class="number">2</span>) <span class="comment"># (B, Ns)</span></span><br><span class="line">        top_view_inds_ = top_view_inds.view(B, num_seed, <span class="number">1</span>, <span class="number">1</span>).expand(-<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>, <span class="number">3</span>).contiguous()</span><br><span class="line">        <span class="comment"># expand代表把(B, M, 1, 1)复制成(B, M, 1, 3)，最后一维共享内存</span></span><br><span class="line">        template_views = generate_grasp_views(self.num_view).to(features.device) <span class="comment"># (V, 3)</span></span><br><span class="line">        template_views = template_views.view(<span class="number">1</span>, <span class="number">1</span>, self.num_view, <span class="number">3</span>).expand(B, num_seed, -<span class="number">1</span>, -<span class="number">1</span>).contiguous() <span class="comment">#(B, Ns, V, 3)</span></span><br><span class="line">        vp_xyz = torch.gather(template_views, <span class="number">2</span>, top_view_inds_).squeeze(<span class="number">2</span>) <span class="comment">#(B, Ns, 3)</span></span><br><span class="line">        <span class="comment"># torch.gather意味着我们可以使用index把V那一维的对应index选出来，然后我们再用squeeze压缩维度</span></span><br><span class="line">        <span class="comment"># 也就是 (B, M, V, 3) =&gt; (B, M, 1, 3) =&gt; (B, M, 3)</span></span><br><span class="line">        vp_xyz_ = vp_xyz.view(-<span class="number">1</span>, <span class="number">3</span>) <span class="comment"># (B * M, 3)</span></span><br><span class="line">        batch_angle = torch.zeros(vp_xyz_.size(<span class="number">0</span>), dtype=vp_xyz.dtype, device=vp_xyz.device)</span><br><span class="line">        <span class="comment"># batch_angle : (B * M, 3)，此时的in-plane rotation</span></span><br><span class="line">        vp_rot = batch_viewpoint_params_to_matrix(-vp_xyz_, batch_angle).view(B, num_seed, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">        <span class="comment"># batch_viewpoint_params_to_matrix是把approach vector和in-plane rotation转化为旋转矩阵</span></span><br><span class="line">        end_points[<span class="string">&#x27;grasp_top_view_inds&#x27;</span>] = top_view_inds</span><br><span class="line">        end_points[<span class="string">&#x27;grasp_top_view_score&#x27;</span>] = top_view_scores</span><br><span class="line">        end_points[<span class="string">&#x27;grasp_top_view_xyz&#x27;</span>] = vp_xyz</span><br><span class="line">        end_points[<span class="string">&#x27;grasp_top_view_rot&#x27;</span>] = vp_rot</span><br><span class="line">        <span class="keyword">return</span> end_points</span><br></pre></td></tr></table></figure>

<p>​    注意到在GraspNet的forward过程中，我们的end_points需要经过process_grasp_labels这个函数。我们先来看看这个函数在做什么，它主要做了几件事情：</p>
<ul>
<li>把物体坐标系下的Grasp投射到标准场景坐标系下，并且聚类到最近的场景系下的标准模板向量（V个approaching vector）</li>
<li>根据聚类结果对(Ns, V, A, D, 3)的第2维度V重排顺序，使得第二维满足相同的顺序，即不同物体的Grasp可以合成一个tensor：(Np’, V, A, D, 3)，其中满足$N_P’=\sum N_P$。</li>
<li>对物体的原先标签Grasp Label做转换，原先的意义是达到稳定抓取的最小摩擦系数，转换成Score时需要满足摩擦系数越大的Grasp的成功率越小，所以其中做了一个归一化的倒数处理。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_grasp_labels</span>(<span class="params">end_points</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; 根据场景中的点和场景中物体的6D Pose处理grasp labels&quot;&quot;&quot;</span></span><br><span class="line">    clouds = end_points[<span class="string">&#x27;input_xyz&#x27;</span>] <span class="comment">#(B, N, 3)</span></span><br><span class="line">    seed_xyzs = end_points[<span class="string">&#x27;fp2_xyz&#x27;</span>] <span class="comment">#(B, Ns, 3)</span></span><br><span class="line">    batch_size, num_samples, _ = seed_xyzs.size()</span><br><span class="line"></span><br><span class="line">    batch_grasp_points = []</span><br><span class="line">    batch_grasp_views = []</span><br><span class="line">    batch_grasp_views_rot = []</span><br><span class="line">    batch_grasp_labels = []</span><br><span class="line">    batch_grasp_offsets = []</span><br><span class="line">    batch_grasp_tolerance = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(batch_size):	<span class="comment"># batch中的每个数据单独处理</span></span><br><span class="line">        seed_xyz = seed_xyzs[i] <span class="comment"># (Ns, 3)</span></span><br><span class="line">        poses = end_points[<span class="string">&#x27;object_poses_list&#x27;</span>][i] <span class="comment"># [&lt;=10, (3, 4)]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># get merged grasp points for label computation</span></span><br><span class="line">        grasp_points_merged = []</span><br><span class="line">        grasp_views_merged = []</span><br><span class="line">        grasp_views_rot_merged = []</span><br><span class="line">        grasp_labels_merged = []</span><br><span class="line">        grasp_offsets_merged = []</span><br><span class="line">        grasp_tolerance_merged = []</span><br><span class="line">        <span class="keyword">for</span> obj_idx, pose <span class="keyword">in</span> <span class="built_in">enumerate</span>(poses):	<span class="comment"># 枚举当前场景中的所有物体</span></span><br><span class="line">            <span class="comment"># 得到每个物体单独时候的Grasps，数量为Np * V * A * D</span></span><br><span class="line">            grasp_points = end_points[<span class="string">&#x27;grasp_points_list&#x27;</span>][i][obj_idx] <span class="comment">#(Np, 3)</span></span><br><span class="line">            grasp_labels = end_points[<span class="string">&#x27;grasp_labels_list&#x27;</span>][i][obj_idx] <span class="comment">#(Np, V, A, D)</span></span><br><span class="line">            grasp_offsets = end_points[<span class="string">&#x27;grasp_offsets_list&#x27;</span>][i][obj_idx] <span class="comment">#(Np, V, A, D, 3)</span></span><br><span class="line">            grasp_tolerance = end_points[<span class="string">&#x27;grasp_tolerance_list&#x27;</span>][i][obj_idx] <span class="comment">#(Np, V, A, D)</span></span><br><span class="line">            _, V, A, D = grasp_labels.size()</span><br><span class="line">            num_grasp_points = grasp_points.size(<span class="number">0</span>)	<span class="comment"># 得到 Np</span></span><br><span class="line">            <span class="comment"># generate and transform template grasp views</span></span><br><span class="line">            <span class="comment"># 我们需要把物体mesh上的模板Grasp投射到当前场景的6D Pose下</span></span><br><span class="line">            grasp_views = generate_grasp_views(V).to(pose.device) </span><br><span class="line">            <span class="comment"># 使用单位球均匀采样方法，得到V个方向向量(V, 3)</span></span><br><span class="line">            grasp_points_trans = transform_point_cloud(grasp_points, pose, <span class="string">&#x27;3x4&#x27;</span>)、</span><br><span class="line">            <span class="comment"># 3x4就是既要旋转又要平移，根据物体在场景中的6D Pose，把grasp的投影到场景中, (Np, 3)</span></span><br><span class="line">            grasp_views_trans = transform_point_cloud(grasp_views, pose[:<span class="number">3</span>,:<span class="number">3</span>], <span class="string">&#x27;3x3&#x27;</span>)</span><br><span class="line">            <span class="comment"># 3x3就是只旋转，我们现在得到了V个场景中对齐的方向向量</span></span><br><span class="line">            angles = torch.zeros(grasp_views.size(<span class="number">0</span>), dtype=grasp_views.dtype, device=grasp_views.device)</span><br><span class="line">            <span class="comment"># 我们把单位向量转化为旋转矩阵，这个转换需要一个额外的自由度，也就in-plane rotation，这也是为什么我们传入了一个全零的angles的理由</span></span><br><span class="line">            grasp_views_rot = batch_viewpoint_params_to_matrix(-grasp_views, angles) <span class="comment">#(V, 3, 3)</span></span><br><span class="line">            <span class="comment"># 这个函数内部，无非就就是把方向向量和标准坐标轴的某一维度对齐，再根据数学算出一个基矢量，然后计算基变换矩阵</span></span><br><span class="line">            grasp_views_rot_trans = torch.matmul(pose[:<span class="number">3</span>,:<span class="number">3</span>], grasp_views_rot) <span class="comment">#(V, 3, 3)</span></span><br><span class="line">            <span class="comment"># 这个矩阵乘以物体的Pose矩阵，就得到了这个Grasp的Approach Vector在场景系下的绝对orn</span></span><br><span class="line">            </span><br><span class="line">            grasp_views_ = grasp_views.transpose(<span class="number">0</span>, <span class="number">1</span>).contiguous().unsqueeze(<span class="number">0</span>)	<span class="comment"># (1, 3, V)</span></span><br><span class="line">            grasp_views_trans_ = grasp_views_trans.transpose(<span class="number">0</span>, <span class="number">1</span>).contiguous().unsqueeze(<span class="number">0</span>)	<span class="comment">#(1, 3, V)</span></span><br><span class="line">       </span><br><span class="line">            view_inds = knn(grasp_views_trans_, grasp_views_, k=<span class="number">1</span>).squeeze() - <span class="number">1</span></span><br><span class="line">        	<span class="comment"># 注意此处ref = grasp_views_trans_(物体坐标系的模板)</span></span><br><span class="line">            <span class="comment"># query = grasp_views_(物体坐标系)</span></span><br><span class="line">            <span class="comment"># 所以是要把物体坐标系下的方向向量分配到场景坐标系的模板方向向量上</span></span><br><span class="line">            <span class="comment"># 因为物体在场景中的6D Pose是任意的，所以导致在场景对齐后，V个模板方向向量也是任意的，此处的KNN就是把场景对齐后的任意方向的V个approaching vector，重新聚类回场景系下的模板(V, 3)，这样场景中所有Grasp的GT都会属于绝对场景坐标系下的V个approaching vector中。</span></span><br><span class="line">            grasp_views_trans = torch.index_select(grasp_views_trans, <span class="number">0</span>, view_inds) <span class="comment">#(V, 3)</span></span><br><span class="line">            grasp_views_trans = grasp_views_trans.unsqueeze(<span class="number">0</span>).expand(num_grasp_points, -<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">            <span class="comment"># (Np, V, 3)，重新计算Np个Grasp的新的方向向量</span></span><br><span class="line">            grasp_views_rot_trans = torch.index_select(grasp_views_rot_trans, <span class="number">0</span>, view_inds) <span class="comment">#(V, 3, 3)</span></span><br><span class="line">            grasp_views_rot_trans = grasp_views_rot_trans.unsqueeze(<span class="number">0</span>).expand(num_grasp_points, -<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">            <span class="comment"># (Np, V, 3, 3)，重新计算Np个Grasp的新的orn</span></span><br><span class="line">            grasp_labels = torch.index_select(grasp_labels, <span class="number">1</span>, view_inds) <span class="comment">#(Np, V, A, D)</span></span><br><span class="line">            grasp_offsets = torch.index_select(grasp_offsets, <span class="number">1</span>, view_inds) <span class="comment">#(Np, V, A, D, 3)</span></span><br><span class="line">            grasp_tolerance = torch.index_select(grasp_tolerance, <span class="number">1</span>, view_inds) <span class="comment">#(Np, V, A, D)</span></span><br><span class="line">            <span class="comment"># 上面三行其实都是在dim=1上重排序号，使其重新满足V这一维度的顺序等于模板Approaching Vector的创建顺序</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># add to list</span></span><br><span class="line">            grasp_points_merged.append(grasp_points_trans)</span><br><span class="line">            grasp_views_merged.append(grasp_views_trans)</span><br><span class="line">            grasp_views_rot_merged.append(grasp_views_rot_trans)</span><br><span class="line">            grasp_labels_merged.append(grasp_labels)</span><br><span class="line">            grasp_offsets_merged.append(grasp_offsets)</span><br><span class="line">            grasp_tolerance_merged.append(grasp_tolerance)</span><br><span class="line">		<span class="comment"># Np&#x27; = sum(Np) for all object in the scene</span></span><br><span class="line">        grasp_points_merged = torch.cat(grasp_points_merged, dim=<span class="number">0</span>) <span class="comment">#(Np&#x27;, 3)</span></span><br><span class="line">        grasp_views_merged = torch.cat(grasp_views_merged, dim=<span class="number">0</span>) <span class="comment">#(Np&#x27;, V, 3)</span></span><br><span class="line">        grasp_views_rot_merged = torch.cat(grasp_views_rot_merged, dim=<span class="number">0</span>) <span class="comment">#(Np&#x27;, V, 3, 3)</span></span><br><span class="line">        grasp_labels_merged = torch.cat(grasp_labels_merged, dim=<span class="number">0</span>) <span class="comment">#(Np&#x27;, V, A, D)</span></span><br><span class="line">        grasp_offsets_merged = torch.cat(grasp_offsets_merged, dim=<span class="number">0</span>) <span class="comment">#(Np&#x27;, V, A, D, 3)</span></span><br><span class="line">        grasp_tolerance_merged = torch.cat(grasp_tolerance_merged, dim=<span class="number">0</span>) <span class="comment">#(Np&#x27;, V, A, D)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute nearest neighbors</span></span><br><span class="line">        seed_xyz_ = seed_xyz.transpose(<span class="number">0</span>, <span class="number">1</span>).contiguous().unsqueeze(<span class="number">0</span>) <span class="comment">#(1, 3, Ns)</span></span><br><span class="line">        grasp_points_merged_ = grasp_points_merged.transpose(<span class="number">0</span>, <span class="number">1</span>).contiguous().unsqueeze(<span class="number">0</span>) <span class="comment">#(1, 3, Np&#x27;)</span></span><br><span class="line">        nn_inds = knn(grasp_points_merged_, seed_xyz_, k=<span class="number">1</span>).squeeze() - <span class="number">1</span> </span><br><span class="line">        <span class="comment"># 一般来说，Np&#x27;通常会有很多个，而Ns = M = 1024，所以此处就是在把每个seed分配到最近的一个grasp point中，这样每个seed就保留了一个最接近的grasp point，这样我们对于每个点有稠密的V * A * D个抓点的标注。</span></span><br><span class="line"></span><br><span class="line">        grasp_points_merged = torch.index_select(grasp_points_merged, <span class="number">0</span>, nn_inds) <span class="comment"># (Ns, 3)</span></span><br><span class="line">        grasp_views_merged = torch.index_select(grasp_views_merged, <span class="number">0</span>, nn_inds) <span class="comment"># (Ns, V, 3)</span></span><br><span class="line">        grasp_views_rot_merged = torch.index_select(grasp_views_rot_merged, <span class="number">0</span>, nn_inds) <span class="comment">#(Ns, V, 3, 3)</span></span><br><span class="line">        grasp_labels_merged = torch.index_select(grasp_labels_merged, <span class="number">0</span>, nn_inds) <span class="comment"># (Ns, V, A, D)</span></span><br><span class="line">        grasp_offsets_merged = torch.index_select(grasp_offsets_merged, <span class="number">0</span>, nn_inds) <span class="comment"># (Ns, V, A, D, 3)</span></span><br><span class="line">        grasp_tolerance_merged = torch.index_select(grasp_tolerance_merged, <span class="number">0</span>, nn_inds) <span class="comment"># (Ns, V, A, D)</span></span><br><span class="line">		<span class="comment"># 以上就是得到了当前这个Batch的稠密标注</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># add to batch</span></span><br><span class="line">        batch_grasp_points.append(grasp_points_merged)</span><br><span class="line">        batch_grasp_views.append(grasp_views_merged)</span><br><span class="line">        batch_grasp_views_rot.append(grasp_views_rot_merged)</span><br><span class="line">        batch_grasp_labels.append(grasp_labels_merged)</span><br><span class="line">        batch_grasp_offsets.append(grasp_offsets_merged)</span><br><span class="line">        batch_grasp_tolerance.append(grasp_tolerance_merged)</span><br><span class="line">		</span><br><span class="line">        </span><br><span class="line">    batch_grasp_points = torch.stack(batch_grasp_points, <span class="number">0</span>) <span class="comment">#(B, Ns, 3)</span></span><br><span class="line">    batch_grasp_views = torch.stack(batch_grasp_views, <span class="number">0</span>) <span class="comment">#(B, Ns, V, 3)</span></span><br><span class="line">    batch_grasp_views_rot = torch.stack(batch_grasp_views_rot, <span class="number">0</span>) <span class="comment">#(B, Ns, V, 3, 3)</span></span><br><span class="line">    batch_grasp_labels = torch.stack(batch_grasp_labels, <span class="number">0</span>) <span class="comment">#(B, Ns, V, A, D)</span></span><br><span class="line">    batch_grasp_offsets = torch.stack(batch_grasp_offsets, <span class="number">0</span>) <span class="comment">#(B, Ns, V, A, D, 3)</span></span><br><span class="line">    batch_grasp_tolerance = torch.stack(batch_grasp_tolerance, <span class="number">0</span>) <span class="comment">#(B, Ns, V, A, D)</span></span><br><span class="line">	<span class="comment"># 得到了所有batch的稠密标注</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># process labels</span></span><br><span class="line">    batch_grasp_widths = batch_grasp_offsets[:,:,:,:,:,<span class="number">2</span>]</span><br><span class="line">    label_mask = (batch_grasp_labels &gt; <span class="number">0</span>) &amp; (batch_grasp_widths &lt;= GRASP_MAX_WIDTH)</span><br><span class="line">    u_max = batch_grasp_labels.<span class="built_in">max</span>()</span><br><span class="line">    <span class="comment"># 此时的grasp_labels的物理意义为：达到一个稳定抓取所需要的最小摩擦系数</span></span><br><span class="line">    batch_grasp_labels[label_mask] = torch.log(u_max / batch_grasp_labels[label_mask])</span><br><span class="line">    <span class="comment"># 我们让摩擦系数最大的Grasp的分数为0，因为所需要的摩擦系数越大，Grasp的可能性越低</span></span><br><span class="line">    <span class="comment"># 因为摩擦系数分为了0.1~1，所以torch.log里最大的情况就是10，也就是grasp_score的最大值是torch.log(10)</span></span><br><span class="line">    batch_grasp_labels[~label_mask] = <span class="number">0</span></span><br><span class="line">    batch_grasp_view_scores, _ = batch_grasp_labels.view(batch_size, num_samples, V, A*D).<span class="built_in">max</span>(dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    end_points[<span class="string">&#x27;batch_grasp_point&#x27;</span>] = batch_grasp_points</span><br><span class="line">    end_points[<span class="string">&#x27;batch_grasp_view&#x27;</span>] = batch_grasp_views</span><br><span class="line">    end_points[<span class="string">&#x27;batch_grasp_view_rot&#x27;</span>] = batch_grasp_views_rot</span><br><span class="line">    end_points[<span class="string">&#x27;batch_grasp_label&#x27;</span>] = batch_grasp_labels</span><br><span class="line">    end_points[<span class="string">&#x27;batch_grasp_offset&#x27;</span>] = batch_grasp_offsets</span><br><span class="line">    end_points[<span class="string">&#x27;batch_grasp_tolerance&#x27;</span>] = batch_grasp_tolerance</span><br><span class="line">    end_points[<span class="string">&#x27;batch_grasp_view_label&#x27;</span>] = batch_grasp_view_scores.<span class="built_in">float</span>()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> end_points</span><br></pre></td></tr></table></figure>

<p>​    GraspNetStage2的结构如下，它主要包含三个模块：</p>
<ul>
<li><p>match_grasp_view_and_label</p>
</li>
<li><p>CloudCrop</p>
</li>
<li><p>并列的两个论文中画出来的网络：OperationNet和ToleranceNet</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GraspNetStage2</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_angle=<span class="number">12</span>, num_depth=<span class="number">4</span>, cylinder_radius=<span class="number">0.05</span>, hmin=-<span class="number">0.02</span>, hmax_list=[<span class="number">0.01</span>,<span class="number">0.02</span>,<span class="number">0.03</span>,<span class="number">0.04</span>], is_training=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.num_angle = num_angle</span><br><span class="line">        self.num_depth = num_depth</span><br><span class="line">        self.is_training = is_training</span><br><span class="line">        self.crop = CloudCrop(nsample=<span class="number">64</span>, seed_feature_dim=<span class="number">3</span>, cylinder_radius=cylinder_radius, hmin=hmin, hmax_list=hmax_list)</span><br><span class="line">        self.operation = OperationNet(num_angle, num_depth)</span><br><span class="line">        self.tolerance = ToleranceNet(num_angle, num_depth)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, end_points</span>):</span></span><br><span class="line">        pointcloud = end_points[<span class="string">&#x27;input_xyz&#x27;</span>]</span><br><span class="line">        <span class="keyword">if</span> self.is_training:</span><br><span class="line">            grasp_top_views_rot, _, _, _, end_points = match_grasp_view_and_label(end_points)</span><br><span class="line">            seed_xyz = end_points[<span class="string">&#x27;batch_grasp_point&#x27;</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            grasp_top_views_rot = end_points[<span class="string">&#x27;grasp_top_view_rot&#x27;</span>]</span><br><span class="line">            seed_xyz = end_points[<span class="string">&#x27;fp2_xyz&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        vp_features = self.crop(seed_xyz, pointcloud, grasp_top_views_rot)</span><br><span class="line">        end_points = self.operation(vp_features, end_points)</span><br><span class="line">        end_points = self.tolerance(vp_features, end_points)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> end_points</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">match_grasp_view_and_label</span>(<span class="params">end_points</span>):</span></span><br><span class="line">    <span class="comment"># 这个函数在做的事情就是，我们已经预测出来了V个approaching vector中最高分的index，那么我们就要从batch_grasp中把对应的Grasp的参数找出来作为当前点的GT往后传递</span></span><br><span class="line">    top_view_inds = end_points[<span class="string">&#x27;grasp_top_view_inds&#x27;</span>] <span class="comment"># (B, Ns)</span></span><br><span class="line">    template_views_rot = end_points[<span class="string">&#x27;batch_grasp_view_rot&#x27;</span>] <span class="comment"># (B, Ns, V, 3, 3)</span></span><br><span class="line">    grasp_labels = end_points[<span class="string">&#x27;batch_grasp_label&#x27;</span>] <span class="comment"># (B, Ns, V, A, D)</span></span><br><span class="line">    grasp_offsets = end_points[<span class="string">&#x27;batch_grasp_offset&#x27;</span>] <span class="comment"># (B, Ns, V, A, D, 3)</span></span><br><span class="line">    grasp_tolerance = end_points[<span class="string">&#x27;batch_grasp_tolerance&#x27;</span>] <span class="comment"># (B, Ns, V, A, D)</span></span><br><span class="line"></span><br><span class="line">    B, Ns, V, A, D = grasp_labels.size()</span><br><span class="line">    top_view_inds_ = top_view_inds.view(B, Ns, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>).expand(-<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">    <span class="comment"># 此时top_view_inds_为(B, Ns, 1, 3, 3)，也就是在V这一维中把最高分的选出来</span></span><br><span class="line">    top_template_views_rot = torch.gather(template_views_rot, <span class="number">2</span>, top_view_inds_).squeeze(<span class="number">2</span>)</span><br><span class="line">    top_view_inds_ = top_view_inds.view(B, Ns, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>).expand(-<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>, A, D)</span><br><span class="line">    top_view_grasp_labels = torch.gather(grasp_labels, <span class="number">2</span>, top_view_inds_).squeeze(<span class="number">2</span>)</span><br><span class="line">    top_view_grasp_tolerance = torch.gather(grasp_tolerance, <span class="number">2</span>, top_view_inds_).squeeze(<span class="number">2</span>)</span><br><span class="line">    top_view_inds_ = top_view_inds.view(B, Ns, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>).expand(-<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>, A, D, <span class="number">3</span>)</span><br><span class="line">    top_view_grasp_offsets = torch.gather(grasp_offsets, <span class="number">2</span>, top_view_inds_).squeeze(<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># top_template_views_rot (B, Ns, 3, 3)</span></span><br><span class="line">    <span class="comment"># top_view_grasp_labels (B, Ns, A, D)</span></span><br><span class="line">    <span class="comment"># top_view_grasp_tolerance (B, Ns, A, D, 3)</span></span><br><span class="line">    <span class="comment"># top_view_grasp_offsets (B, Ns, A, D)</span></span><br><span class="line"></span><br><span class="line">    end_points[<span class="string">&#x27;batch_grasp_view_rot&#x27;</span>] = top_template_views_rot</span><br><span class="line">    end_points[<span class="string">&#x27;batch_grasp_label&#x27;</span>] = top_view_grasp_labels</span><br><span class="line">    end_points[<span class="string">&#x27;batch_grasp_offset&#x27;</span>] = top_view_grasp_offsets</span><br><span class="line">    end_points[<span class="string">&#x27;batch_grasp_tolerance&#x27;</span>] = top_view_grasp_tolerance</span><br><span class="line">	<span class="comment"># 从此以后，这些数据从原先的V个，只保留了分数最高的那一个了</span></span><br><span class="line">    <span class="keyword">return</span> top_template_views_rot, top_view_grasp_labels, top_view_grasp_offsets, top_view_grasp_tolerance, end_points</span><br></pre></td></tr></table></figure>

<p>​    接下来CloudCrop模块：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CloudCrop</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; Cylinder group and align for grasp configure estimation. Return a list of grouped points with different cropping depths.</span></span><br><span class="line"><span class="string">        Input:</span></span><br><span class="line"><span class="string">            nsample: [int]</span></span><br><span class="line"><span class="string">                sample number in a group</span></span><br><span class="line"><span class="string">            seed_feature_dim: [int]</span></span><br><span class="line"><span class="string">                number of channels of grouped points</span></span><br><span class="line"><span class="string">            cylinder_radius: [float]</span></span><br><span class="line"><span class="string">                radius of the cylinder space</span></span><br><span class="line"><span class="string">            hmin: [float]</span></span><br><span class="line"><span class="string">                height of the bottom surface</span></span><br><span class="line"><span class="string">            hmax_list: [list of float]</span></span><br><span class="line"><span class="string">                list of heights of the upper surface</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, nsample, seed_feature_dim, cylinder_radius=<span class="number">0.05</span>, hmin=-<span class="number">0.02</span>, hmax_list=[<span class="number">0.01</span>,<span class="number">0.02</span>,<span class="number">0.03</span>,<span class="number">0.04</span>]</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.nsample = nsample</span><br><span class="line">        self.in_dim = seed_feature_dim</span><br><span class="line">        self.cylinder_radius = cylinder_radius</span><br><span class="line">        mlps = [self.in_dim, <span class="number">64</span>, <span class="number">128</span>, <span class="number">256</span>]</span><br><span class="line">        </span><br><span class="line">        self.groupers = []</span><br><span class="line">        <span class="keyword">for</span> hmax <span class="keyword">in</span> hmax_list:</span><br><span class="line">            self.groupers.append(CylinderQueryAndGroup(cylinder_radius, hmin, hmax, nsample, use_xyz=<span class="literal">True</span>))</span><br><span class="line">        self.mlps = pt_utils.SharedMLP(mlps, bn=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, seed_xyz, pointcloud, vp_rot</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot; Forward pass.</span></span><br><span class="line"><span class="string">            Input:</span></span><br><span class="line"><span class="string">                seed_xyz:   (B, Ns, 3), coordinates of seed points</span></span><br><span class="line"><span class="string">                pointcloud: (B, Ns, 3), the points to be cropped</span></span><br><span class="line"><span class="string">                vp_rot:     (B, Ns, 3, 3), rotation matrices generated from approach vectors</span></span><br><span class="line"><span class="string">            Output:</span></span><br><span class="line"><span class="string">                vp_features: (B, num_features, Ns,num_depth), features of grouped points in different depths</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        B, num_seed, _, _ = vp_rot.size()</span><br><span class="line">        num_depth = <span class="built_in">len</span>(self.groupers)</span><br><span class="line">        grouped_features = []</span><br><span class="line">        <span class="keyword">for</span> grouper <span class="keyword">in</span> self.groupers:	<span class="comment"># 枚举D个grouper</span></span><br><span class="line">            grouped_features.append(grouper(pointcloud, seed_xyz, vp_rot)) </span><br><span class="line">            <span class="comment"># (B, 3, Ns, nsample)</span></span><br><span class="line">        grouped_features = torch.stack(grouped_features, dim=<span class="number">3</span>) </span><br><span class="line">        <span class="comment"># (B, 3, Ns, D, nsample)</span></span><br><span class="line">        grouped_features = grouped_features.view(B, -<span class="number">1</span>, num_seed*num_depth, self.nsample) </span><br><span class="line">        <span class="comment"># (B, 3, Ns * D, nsample)</span></span><br><span class="line">        vp_features = self.mlps(grouped_features) </span><br><span class="line">        <span class="comment"># (B, mlps[-1], Ns * D, nsample)</span></span><br><span class="line">        vp_features = F.max_pool2d(vp_features, kernel_size=[<span class="number">1</span>, vp_features.size(<span class="number">3</span>)])</span><br><span class="line">        <span class="comment"># 圆筒聚类后，对聚类中的点做max_pool2d来聚合成一个cluster feature</span></span><br><span class="line">        <span class="comment"># (B, mlps[-1], Ns * D, 1)</span></span><br><span class="line">        vp_features = vp_features.view(B, -<span class="number">1</span>, num_seed, num_depth)</span><br><span class="line">        <span class="comment"># (B, mlps[-1], Ns, D)</span></span><br><span class="line">		<span class="comment"># 这个模组在做的事情就是把D维根据不同的深度提取出不同的特征，放到dim=1中。</span></span><br><span class="line">        <span class="keyword">return</span> vp_features</span><br></pre></td></tr></table></figure>

<p>​    在此之中，用到了一个CylinderQueryAndGroup模块，我们进一步往下探索。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CylinderQueryAndGroup</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Groups with a cylinder query of radius and height</span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ---------</span></span><br><span class="line"><span class="string">    radius : float32</span></span><br><span class="line"><span class="string">        Radius of cylinder</span></span><br><span class="line"><span class="string">    hmin, hmax: float32</span></span><br><span class="line"><span class="string">        endpoints of cylinder height in x-rotation axis</span></span><br><span class="line"><span class="string">    nsample : int32</span></span><br><span class="line"><span class="string">        Maximum number of features to gather in the ball</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, radius, hmin, hmax, nsample, use_xyz=<span class="literal">True</span>, ret_grouped_xyz=<span class="literal">False</span>, normalize_xyz=<span class="literal">False</span>, rotate_xyz=<span class="literal">True</span>, sample_uniformly=<span class="literal">False</span>, ret_unique_cnt=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(CylinderQueryAndGroup, self).__init__()</span><br><span class="line">        self.radius, self.nsample, self.hmin, self.hmax, = radius, nsample, hmin, hmax</span><br><span class="line">        self.use_xyz = use_xyz</span><br><span class="line">        self.ret_grouped_xyz = ret_grouped_xyz</span><br><span class="line">        self.normalize_xyz = normalize_xyz</span><br><span class="line">        self.rotate_xyz = rotate_xyz</span><br><span class="line">        self.sample_uniformly = sample_uniformly</span><br><span class="line">        self.ret_unique_cnt = ret_unique_cnt</span><br><span class="line">        <span class="keyword">if</span> self.ret_unique_cnt:</span><br><span class="line">            <span class="keyword">assert</span>(self.sample_uniformly)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, xyz, new_xyz, rot, features=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        xyz : 点云坐标      (B, N, 3)</span></span><br><span class="line"><span class="string">        new_xyz : 抓点中心  (B, npoint, 3)</span></span><br><span class="line"><span class="string">        rot : 抓点的旋转矩阵 (B, npoint, 3, 3)</span></span><br><span class="line"><span class="string">        features : torch.Tensor</span></span><br><span class="line"><span class="string">            Descriptors of the features (B, C, N)</span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        new_features : torch.Tensor</span></span><br><span class="line"><span class="string">            (B, 3 + C, npoint, nsample) tensor</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        B, npoint, _ = new_xyz.size()</span><br><span class="line">        idx = cylinder_query(self.radius, self.hmin, self.hmax, self.nsample, xyz, new_xyz, rot.view(B, npoint, <span class="number">9</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.sample_uniformly:</span><br><span class="line">            unique_cnt = torch.zeros((idx.shape[<span class="number">0</span>], idx.shape[<span class="number">1</span>]))</span><br><span class="line">            <span class="keyword">for</span> i_batch <span class="keyword">in</span> <span class="built_in">range</span>(idx.shape[<span class="number">0</span>]):</span><br><span class="line">                <span class="keyword">for</span> i_region <span class="keyword">in</span> <span class="built_in">range</span>(idx.shape[<span class="number">1</span>]):</span><br><span class="line">                    unique_ind = torch.unique(idx[i_batch, i_region, :])</span><br><span class="line">                    num_unique = unique_ind.shape[<span class="number">0</span>]</span><br><span class="line">                    unique_cnt[i_batch, i_region] = num_unique</span><br><span class="line">                    sample_ind = torch.randint(<span class="number">0</span>, num_unique, (self.nsample - num_unique,),dtype=torch.long)</span><br><span class="line">                    all_ind = torch.cat((unique_ind, unique_ind[sample_ind]))</span><br><span class="line">                    idx[i_batch, i_region, :] = all_ind</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        xyz_trans = xyz.transpose(<span class="number">1</span>, <span class="number">2</span>).contiguous()</span><br><span class="line">        grouped_xyz = grouping_operation(xyz_trans, idx)  <span class="comment"># (B, 3, npoint, nsample)</span></span><br><span class="line">        grouped_xyz -= new_xyz.transpose(<span class="number">1</span>, <span class="number">2</span>).unsqueeze(-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> self.normalize_xyz:</span><br><span class="line">            grouped_xyz /= self.radius</span><br><span class="line">        <span class="keyword">if</span> self.rotate_xyz:</span><br><span class="line">            grouped_xyz_ = grouped_xyz.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).contiguous() <span class="comment"># (B, npoint, nsample, 3)</span></span><br><span class="line">            grouped_xyz_ = torch.matmul(grouped_xyz_, rot)</span><br><span class="line">            grouped_xyz = grouped_xyz_.permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>).contiguous()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> features <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            grouped_features = grouping_operation(features, idx)</span><br><span class="line">            <span class="keyword">if</span> self.use_xyz:</span><br><span class="line">                new_features = torch.cat(</span><br><span class="line">                    [grouped_xyz, grouped_features], dim=<span class="number">1</span></span><br><span class="line">                )  <span class="comment"># (B, C + 3, npoint, nsample)</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                new_features = grouped_features</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">assert</span> (self.use_xyz), <span class="string">&quot;Cannot have not features and not use xyz as a feature!&quot;</span></span><br><span class="line">            new_features = grouped_xyz</span><br><span class="line"></span><br><span class="line">        ret = [new_features]</span><br><span class="line">        <span class="keyword">if</span> self.ret_grouped_xyz:</span><br><span class="line">            ret.append(grouped_xyz)</span><br><span class="line">        <span class="keyword">if</span> self.ret_unique_cnt:</span><br><span class="line">            ret.append(unique_cnt)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(ret) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> ret[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">tuple</span>(ret)</span><br></pre></td></tr></table></figure>

<p>​    为了理解其中cylinder_query的作用，我们看到其CUDA实现：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//我们先尝试理解PointNet++中的ball_query的实现</span></span><br><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">query_ball_point_kernel</span><span class="params">(<span class="keyword">int</span> b, <span class="keyword">int</span> n, <span class="keyword">int</span> m, <span class="keyword">float</span> radius,</span></span></span><br><span class="line"><span class="params"><span class="function">                                        <span class="keyword">int</span> nsample,</span></span></span><br><span class="line"><span class="params"><span class="function">                                        <span class="keyword">const</span> <span class="keyword">float</span> *__restrict__ new_xyz,	<span class="comment">//query</span></span></span></span><br><span class="line"><span class="params"><span class="function">                                        <span class="keyword">const</span> <span class="keyword">float</span> *__restrict__ xyz,		<span class="comment">//原先点</span></span></span></span><br><span class="line"><span class="params"><span class="function">                                        <span class="keyword">int</span> *__restrict__ idx)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> batch_index = blockIdx.x;</span><br><span class="line">  xyz += batch_index * n * <span class="number">3</span>;</span><br><span class="line">  new_xyz += batch_index * m * <span class="number">3</span>;</span><br><span class="line">  idx += m * nsample * batch_index;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span> index = threadIdx.x;</span><br><span class="line">  <span class="keyword">int</span> stride = blockDim.x;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">float</span> radius2 = radius * radius;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> j = index; j &lt; m; j += stride) &#123;</span><br><span class="line">    <span class="keyword">float</span> new_x = new_xyz[j * <span class="number">3</span> + <span class="number">0</span>];</span><br><span class="line">    <span class="keyword">float</span> new_y = new_xyz[j * <span class="number">3</span> + <span class="number">1</span>];</span><br><span class="line">    <span class="keyword">float</span> new_z = new_xyz[j * <span class="number">3</span> + <span class="number">2</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>, cnt = <span class="number">0</span>; k &lt; n &amp;&amp; cnt &lt; nsample; ++k) &#123;	<span class="comment">//枚举原先的每个点</span></span><br><span class="line">      <span class="keyword">float</span> x = xyz[k * <span class="number">3</span> + <span class="number">0</span>];</span><br><span class="line">      <span class="keyword">float</span> y = xyz[k * <span class="number">3</span> + <span class="number">1</span>];</span><br><span class="line">      <span class="keyword">float</span> z = xyz[k * <span class="number">3</span> + <span class="number">2</span>];</span><br><span class="line">      <span class="keyword">float</span> d2 = (new_x - x) * (new_x - x) + (new_y - y) * (new_y - y) +</span><br><span class="line">                 (new_z - z) * (new_z - z);	<span class="comment">//计算和Query的距离</span></span><br><span class="line">      <span class="keyword">if</span> (d2 &lt; radius2) &#123;</span><br><span class="line">        <span class="keyword">if</span> (cnt == <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="keyword">for</span> (<span class="keyword">int</span> l = <span class="number">0</span>; l &lt; nsample; ++l) &#123;	<span class="comment">// 小于ball半径的情况下，就加到idx中，并且第一次把idx中的值全部赋值为k</span></span><br><span class="line">            idx[j * nsample + l] = k;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        idx[j * nsample + cnt] = k;</span><br><span class="line">        ++cnt;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">query_cylinder_point_kernel</span><span class="params">(<span class="keyword">int</span> b, <span class="keyword">int</span> n <span class="comment">/*xyz.size(1)*/</span>, <span class="keyword">int</span> m<span class="comment">/*new_xyz.size(1)*/</span>, <span class="keyword">float</span> radius, <span class="keyword">float</span> hmin, <span class="keyword">float</span> hmax,</span></span></span><br><span class="line"><span class="params"><span class="function">                                        <span class="keyword">int</span> nsample,</span></span></span><br><span class="line"><span class="params"><span class="function">                                        <span class="keyword">const</span> <span class="keyword">float</span> *__restrict__ new_xyz,	<span class="comment">//抓点中心</span></span></span></span><br><span class="line"><span class="params"><span class="function">                                        <span class="keyword">const</span> <span class="keyword">float</span> *__restrict__ xyz,	<span class="comment">//点云</span></span></span></span><br><span class="line"><span class="params"><span class="function">                                        <span class="keyword">const</span> <span class="keyword">float</span> *__restrict__ rot,</span></span></span><br><span class="line"><span class="params"><span class="function">                                        <span class="keyword">int</span> *__restrict__ idx)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> batch_index = blockIdx.x;</span><br><span class="line">  xyz += batch_index * n * <span class="number">3</span>;	<span class="comment">// 访问到当前batch的点云数据偏移量，也就是xyz[batch*n*3]</span></span><br><span class="line">  new_xyz += batch_index * m * <span class="number">3</span>;	<span class="comment">// 访问到当前batch的抓点数据偏移量，也就是new_xyz[batch*m*3]</span></span><br><span class="line">  rot += batch_index * m * <span class="number">9</span>;</span><br><span class="line">  idx += m * nsample * batch_index;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span> index = threadIdx.x;	<span class="comment">//当前Block中的线程ID</span></span><br><span class="line">  <span class="keyword">int</span> stride = blockDim.x;	<span class="comment">//当前Grid中的Thread Block ID，注意调用这个kernel函数的时候传入的Grid和Block都是一维的</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">float</span> radius2 = radius * radius;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> j = index; j &lt; m; j += stride) &#123;	<span class="comment">//Query中的每个Grasp Center Point</span></span><br><span class="line">    <span class="keyword">float</span> new_x = new_xyz[j * <span class="number">3</span> + <span class="number">0</span>];</span><br><span class="line">    <span class="keyword">float</span> new_y = new_xyz[j * <span class="number">3</span> + <span class="number">1</span>];</span><br><span class="line">    <span class="keyword">float</span> new_z = new_xyz[j * <span class="number">3</span> + <span class="number">2</span>];</span><br><span class="line">    <span class="keyword">float</span> r0 = rot[j * <span class="number">9</span> + <span class="number">0</span>];</span><br><span class="line">    <span class="keyword">float</span> r1 = rot[j * <span class="number">9</span> + <span class="number">1</span>];</span><br><span class="line">    <span class="keyword">float</span> r2 = rot[j * <span class="number">9</span> + <span class="number">2</span>];</span><br><span class="line">    <span class="keyword">float</span> r3 = rot[j * <span class="number">9</span> + <span class="number">3</span>];</span><br><span class="line">    <span class="keyword">float</span> r4 = rot[j * <span class="number">9</span> + <span class="number">4</span>];</span><br><span class="line">    <span class="keyword">float</span> r5 = rot[j * <span class="number">9</span> + <span class="number">5</span>];</span><br><span class="line">    <span class="keyword">float</span> r6 = rot[j * <span class="number">9</span> + <span class="number">6</span>];</span><br><span class="line">    <span class="keyword">float</span> r7 = rot[j * <span class="number">9</span> + <span class="number">7</span>];</span><br><span class="line">    <span class="keyword">float</span> r8 = rot[j * <span class="number">9</span> + <span class="number">8</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>, cnt = <span class="number">0</span>; k &lt; n &amp;&amp; cnt &lt; nsample; ++k) &#123;	<span class="comment">//枚举点云中的每个点</span></span><br><span class="line">      <span class="keyword">float</span> x = xyz[k * <span class="number">3</span> + <span class="number">0</span>] - new_x;</span><br><span class="line">      <span class="keyword">float</span> y = xyz[k * <span class="number">3</span> + <span class="number">1</span>] - new_y;</span><br><span class="line">      <span class="keyword">float</span> z = xyz[k * <span class="number">3</span> + <span class="number">2</span>] - new_z;</span><br><span class="line">      <span class="keyword">float</span> x_rot = r0 * x + r3 * y + r6 * z;</span><br><span class="line">      <span class="keyword">float</span> y_rot = r1 * x + r4 * y + r7 * z;</span><br><span class="line">      <span class="keyword">float</span> z_rot = r2 * x + r5 * y + r8 * z;</span><br><span class="line">      <span class="comment">// 把裁剪采样过的点云变换到夹爪坐标系里</span></span><br><span class="line">      <span class="keyword">float</span> d2 = y_rot * y_rot + z_rot * z_rot;	<span class="comment">//沿着圆柱切向量的半径计算</span></span><br><span class="line">      <span class="keyword">if</span> (d2 &lt; radius2 &amp;&amp; x_rot &gt; hmin &amp;&amp; x_rot &lt; hmax) &#123;	<span class="comment">//沿着圆柱法向量的裁剪</span></span><br><span class="line">        <span class="keyword">if</span> (cnt == <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="keyword">for</span> (<span class="keyword">int</span> l = <span class="number">0</span>; l &lt; nsample; ++l) &#123;</span><br><span class="line">            idx[j * nsample + l] = k;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        idx[j * nsample + cnt] = k;</span><br><span class="line">        ++cnt;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>​    所以上述CylinderQuery的意义就是在圆柱范围内对点做聚类。</p>
<p>​    接下来是OperationNet和ToleranceNet：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OperationNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; Grasp configure estimation.</span></span><br><span class="line"><span class="string">        Input:</span></span><br><span class="line"><span class="string">            num_angle: [int]</span></span><br><span class="line"><span class="string">                number of in-plane rotation angle classes</span></span><br><span class="line"><span class="string">                the value of the i-th class --&gt; i*PI/num_angle (i=0,...,num_angle-1)</span></span><br><span class="line"><span class="string">            num_depth: [int]</span></span><br><span class="line"><span class="string">                number of gripper depth classes</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_angle, num_depth</span>):</span></span><br><span class="line">        <span class="comment"># Output:</span></span><br><span class="line">        <span class="comment"># scores(num_angle)</span></span><br><span class="line">        <span class="comment"># angle class (num_angle)</span></span><br><span class="line">        <span class="comment"># width (num_angle)</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.num_angle = num_angle</span><br><span class="line">        self.num_depth = num_depth</span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Conv1d(<span class="number">256</span>, <span class="number">128</span>, <span class="number">1</span>)</span><br><span class="line">        self.conv2 = nn.Conv1d(<span class="number">128</span>, <span class="number">128</span>, <span class="number">1</span>)</span><br><span class="line">        self.conv3 = nn.Conv1d(<span class="number">128</span>, <span class="number">3</span>*num_angle, <span class="number">1</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm1d(<span class="number">128</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm1d(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, vp_features, end_points</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot; Forward pass.</span></span><br><span class="line"><span class="string">            Input:</span></span><br><span class="line"><span class="string">                vp_features:  (B, mlps[-1], Ns, D)    features of grouped points in different depths</span></span><br><span class="line"><span class="string">                end_points: [dict]</span></span><br><span class="line"><span class="string">            Output:</span></span><br><span class="line"><span class="string">                end_points: [dict]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 在这个函数中，我们已经确定了Ns和D的情况下，尝试把in-plane angle多分类出来。</span></span><br><span class="line">        B, _, num_seed, num_depth = vp_features.size()</span><br><span class="line">        vp_features = vp_features.view(B, -<span class="number">1</span>, num_seed*num_depth)	</span><br><span class="line">        <span class="comment"># (B, mlps[-1], Ns * D)，在默认情况下为(B, 256, Ns * 4)</span></span><br><span class="line">        vp_features = F.relu(self.bn1(self.conv1(vp_features)), inplace=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># (B, 256, 256) =&gt; (B, 128, 256)</span></span><br><span class="line">        vp_features = F.relu(self.bn2(self.conv2(vp_features)), inplace=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># (B, 128, 256) =&gt; (B, 128, 256)</span></span><br><span class="line">        vp_features = self.conv3(vp_features)</span><br><span class="line">        <span class="comment"># (B, 128, 256) =&gt; (B, 3 * A, 256) 也就是 (B, 3 * A, Ns * D)</span></span><br><span class="line">        vp_features = vp_features.view(B, -<span class="number">1</span>, num_seed, num_depth)</span><br><span class="line">        <span class="comment"># (B, 3 * A, Ns, D)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># split prediction</span></span><br><span class="line">        end_points[<span class="string">&#x27;grasp_score_pred&#x27;</span>] = vp_features[:, <span class="number">0</span>:self.num_angle]</span><br><span class="line">        end_points[<span class="string">&#x27;grasp_angle_cls_pred&#x27;</span>] = vp_features[:, self.num_angle:<span class="number">2</span>*self.num_angle]</span><br><span class="line">        end_points[<span class="string">&#x27;grasp_width_pred&#x27;</span>] = vp_features[:, <span class="number">2</span>*self.num_angle:<span class="number">3</span>*self.num_angle]</span><br><span class="line">        <span class="comment"># 拆成了三个(B, A, Ns, D)</span></span><br><span class="line">        <span class="keyword">return</span> end_points</span><br><span class="line">    </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ToleranceNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; Grasp tolerance prediction.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">        Input:</span></span><br><span class="line"><span class="string">            num_angle: [int]</span></span><br><span class="line"><span class="string">                number of in-plane rotation angle classes</span></span><br><span class="line"><span class="string">                the value of the i-th class --&gt; i*PI/num_angle (i=0,...,num_angle-1)</span></span><br><span class="line"><span class="string">            num_depth: [int]</span></span><br><span class="line"><span class="string">                number of gripper depth classes</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_angle, num_depth</span>):</span></span><br><span class="line">        <span class="comment"># Output:</span></span><br><span class="line">        <span class="comment"># tolerance (num_angle)</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = nn.Conv1d(<span class="number">256</span>, <span class="number">128</span>, <span class="number">1</span>)</span><br><span class="line">        self.conv2 = nn.Conv1d(<span class="number">128</span>, <span class="number">128</span>, <span class="number">1</span>)</span><br><span class="line">        self.conv3 = nn.Conv1d(<span class="number">128</span>, num_angle, <span class="number">1</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm1d(<span class="number">128</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm1d(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, vp_features, end_points</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot; Forward pass.</span></span><br><span class="line"><span class="string">            Input:</span></span><br><span class="line"><span class="string">                vp_features: [torch.FloatTensor, (batch_size,num_seed,3)]</span></span><br><span class="line"><span class="string">                    features of grouped points in different depths</span></span><br><span class="line"><span class="string">                end_points: [dict]</span></span><br><span class="line"><span class="string">            Output:</span></span><br><span class="line"><span class="string">                end_points: [dict]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        B, _, num_seed, num_depth = vp_features.size()</span><br><span class="line">        vp_features = vp_features.view(B, -<span class="number">1</span>, num_seed*num_depth)</span><br><span class="line">        vp_features = F.relu(self.bn1(self.conv1(vp_features)), inplace=<span class="literal">True</span>)</span><br><span class="line">        vp_features = F.relu(self.bn2(self.conv2(vp_features)), inplace=<span class="literal">True</span>)</span><br><span class="line">        vp_features = self.conv3(vp_features)</span><br><span class="line">        vp_features = vp_features.view(B, -<span class="number">1</span>, num_seed, num_depth)</span><br><span class="line">        end_points[<span class="string">&#x27;grasp_tolerance_pred&#x27;</span>] = vp_features</span><br><span class="line">        <span class="comment"># (B, num_angle, Ns, num_depth)</span></span><br><span class="line">        <span class="keyword">return</span> end_points</span><br></pre></td></tr></table></figure>

<p>​    到这里为止，GraspNet的前向传播过程全部结束。我们接下来需要通过pred_decode对预测的end_points字典解码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pred_decode</span>(<span class="params">end_points</span>):</span></span><br><span class="line">    batch_size = <span class="built_in">len</span>(end_points[<span class="string">&#x27;point_clouds&#x27;</span>])</span><br><span class="line">    grasp_preds = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(batch_size):</span><br><span class="line">        <span class="comment">## load predictions</span></span><br><span class="line">        objectness_score = end_points[<span class="string">&#x27;objectness_score&#x27;</span>][i].<span class="built_in">float</span>()</span><br><span class="line">        grasp_score = end_points[<span class="string">&#x27;grasp_score_pred&#x27;</span>][i].<span class="built_in">float</span>()</span><br><span class="line">        grasp_angle_class_score = end_points[<span class="string">&#x27;grasp_angle_cls_pred&#x27;</span>][i]</span><br><span class="line">        grasp_width = <span class="number">1.2</span> * end_points[<span class="string">&#x27;grasp_width_pred&#x27;</span>][i]</span><br><span class="line">        grasp_width = torch.clamp(grasp_width, <span class="built_in">min</span>=<span class="number">0</span>, <span class="built_in">max</span>=GRASP_MAX_WIDTH)</span><br><span class="line">        grasp_tolerance = end_points[<span class="string">&#x27;grasp_tolerance_pred&#x27;</span>][i]</span><br><span class="line">        <span class="comment"># 以上四个都是网络预测的(A, Ns, D)的Grasp参数</span></span><br><span class="line">        grasp_center = end_points[<span class="string">&#x27;fp2_xyz&#x27;</span>][i].<span class="built_in">float</span>()					<span class="comment"># (Ns, 3)</span></span><br><span class="line">        approaching = -end_points[<span class="string">&#x27;grasp_top_view_xyz&#x27;</span>][i].<span class="built_in">float</span>()		<span class="comment"># (Ns, 3)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">## slice preds by angle</span></span><br><span class="line">        <span class="comment"># grasp angle</span></span><br><span class="line">        grasp_angle_class = torch.argmax(grasp_angle_class_score, <span class="number">0</span>)</span><br><span class="line">        <span class="comment"># 得到最高分数的in-plane rotation angle类，也就是(1, Ns, D)</span></span><br><span class="line">        grasp_angle = grasp_angle_class.<span class="built_in">float</span>() / <span class="number">12</span> * np.pi</span><br><span class="line">        <span class="comment"># 转换成对应的in-plane rotation angle</span></span><br><span class="line">        <span class="comment"># grasp score &amp; width &amp; tolerance</span></span><br><span class="line">        grasp_angle_class_ = grasp_angle_class.unsqueeze(<span class="number">0</span>)</span><br><span class="line">        <span class="comment"># 这是 (Ns, D) 的indx</span></span><br><span class="line">        grasp_score = torch.gather(grasp_score, <span class="number">0</span>, grasp_angle_class_).squeeze(<span class="number">0</span>)</span><br><span class="line">        grasp_width = torch.gather(grasp_width, <span class="number">0</span>, grasp_angle_class_).squeeze(<span class="number">0</span>)</span><br><span class="line">        grasp_tolerance = torch.gather(grasp_tolerance, <span class="number">0</span>, grasp_angle_class_).squeeze(<span class="number">0</span>)</span><br><span class="line">		<span class="comment"># 对每个Ns和D得到了一个angle, (Ns, D)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">## slice preds by score/depth</span></span><br><span class="line">        <span class="comment"># grasp depth</span></span><br><span class="line">        grasp_depth_class = torch.argmax(grasp_score, <span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># 在D这个维度，根据grasp_score来选出分数最高的深度</span></span><br><span class="line">        <span class="comment"># (Ns, 1)</span></span><br><span class="line">        grasp_depth = (grasp_depth_class.<span class="built_in">float</span>()+<span class="number">1</span>) * <span class="number">0.01</span></span><br><span class="line">        <span class="comment"># 得到(Ns, 1)的depth</span></span><br><span class="line">        <span class="comment"># grasp score &amp; angle &amp; width &amp; tolerance</span></span><br><span class="line">        grasp_score = torch.gather(grasp_score, <span class="number">1</span>, grasp_depth_class)</span><br><span class="line">        grasp_angle = torch.gather(grasp_angle, <span class="number">1</span>, grasp_depth_class)</span><br><span class="line">        grasp_width = torch.gather(grasp_width, <span class="number">1</span>, grasp_depth_class)</span><br><span class="line">        grasp_tolerance = torch.gather(grasp_tolerance, <span class="number">1</span>, grasp_depth_class)</span><br><span class="line">        <span class="comment"># 以上四个都是(Ns， 1)，每个seed对应唯一一个分数最高的Grasp</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">## slice preds by objectness</span></span><br><span class="line">        objectness_pred = torch.argmax(objectness_score, <span class="number">0</span>)</span><br><span class="line">        <span class="comment"># 对每个点的objectness做判断</span></span><br><span class="line">        objectness_mask = (objectness_pred==<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 根据objectness预测结果得到mask</span></span><br><span class="line">        grasp_score = grasp_score[objectness_mask]</span><br><span class="line">        grasp_width = grasp_width[objectness_mask]</span><br><span class="line">        grasp_depth = grasp_depth[objectness_mask]</span><br><span class="line">        approaching = approaching[objectness_mask]</span><br><span class="line">        grasp_angle = grasp_angle[objectness_mask]</span><br><span class="line">        grasp_center = grasp_center[objectness_mask]</span><br><span class="line">        grasp_tolerance = grasp_tolerance[objectness_mask]</span><br><span class="line">        <span class="comment"># 如果objectness预测没有物体，那么Grasp的所有参数置为空</span></span><br><span class="line">        grasp_score = grasp_score * grasp_tolerance / GRASP_MAX_TOLERANCE</span><br><span class="line">        <span class="comment"># 真正Grasp的分数，要考虑到grasp_tolerance的影响，这里就简单的加权乘了一下</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">## convert to rotation matrix</span></span><br><span class="line">        Ns = grasp_angle.size(<span class="number">0</span>)</span><br><span class="line">        approaching_ = approaching.view(Ns, <span class="number">3</span>)</span><br><span class="line">        grasp_angle_ = grasp_angle.view(Ns)</span><br><span class="line">        rotation_matrix = batch_viewpoint_params_to_matrix(approaching_, grasp_angle_)</span><br><span class="line">        rotation_matrix = rotation_matrix.view(Ns, <span class="number">9</span>)</span><br><span class="line">        <span class="comment">#根据我们的预测，把Ns个Grasp的approaching vector和grasp_angle_组合得到(Ns, 9)的旋转矩阵</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># merge preds</span></span><br><span class="line">        grasp_height = <span class="number">0.02</span> * torch.ones_like(grasp_score)</span><br><span class="line">        <span class="comment"># 此处ones_like就是创建Ns个0.02的元素，也就是我们认为Grasp_height恒为2cm</span></span><br><span class="line">        obj_ids = -<span class="number">1</span> * torch.ones_like(grasp_score)</span><br><span class="line">        grasp_preds.append(torch.cat([grasp_score, grasp_width, grasp_height, grasp_depth, rotation_matrix, grasp_center, obj_ids], axis=-<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> grasp_preds</span><br></pre></td></tr></table></figure>

<h2 id="loss-py"><a href="#loss-py" class="headerlink" title="loss.py"></a>loss.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_loss</span>(<span class="params">end_points</span>):</span></span><br><span class="line">    <span class="comment"># 正如论文所提到的，最终的loss分为三部分</span></span><br><span class="line">    objectness_loss, end_points = compute_objectness_loss(end_points)</span><br><span class="line">    view_loss, end_points = compute_view_loss(end_points)</span><br><span class="line">    grasp_loss, end_points = compute_grasp_loss(end_points)</span><br><span class="line">    loss = objectness_loss + view_loss + <span class="number">0.2</span> * grasp_loss</span><br><span class="line">    end_points[<span class="string">&#x27;loss/overall_loss&#x27;</span>] = loss</span><br><span class="line">    <span class="keyword">return</span> loss, end_points</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_objectness_loss</span>(<span class="params">end_points</span>):</span></span><br><span class="line">    criterion = nn.CrossEntropyLoss(reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line">    objectness_score = end_points[<span class="string">&#x27;objectness_score&#x27;</span>]	<span class="comment"># (B, Ns, 1)</span></span><br><span class="line">    objectness_label = end_points[<span class="string">&#x27;objectness_label&#x27;</span>]	<span class="comment"># (B, M, 1)</span></span><br><span class="line">    fp2_inds = end_points[<span class="string">&#x27;fp2_inds&#x27;</span>].long()</span><br><span class="line">    objectness_label = torch.gather(objectness_label, <span class="number">1</span>, fp2_inds)	<span class="comment"># (B, Ns, 1)</span></span><br><span class="line">    loss = criterion(objectness_score, objectness_label)</span><br><span class="line">    <span class="comment"># 此处就是对Ns个点做二分类的交叉熵</span></span><br><span class="line"></span><br><span class="line">    end_points[<span class="string">&#x27;loss/stage1_objectness_loss&#x27;</span>] = loss</span><br><span class="line">    objectness_pred = torch.argmax(objectness_score, <span class="number">1</span>)</span><br><span class="line">    end_points[<span class="string">&#x27;stage1_objectness_acc&#x27;</span>] = (objectness_pred == objectness_label.long()).<span class="built_in">float</span>().mean()</span><br><span class="line">	<span class="comment"># 精度</span></span><br><span class="line">    end_points[<span class="string">&#x27;stage1_objectness_prec&#x27;</span>] = (objectness_pred == objectness_label.long())[objectness_pred == <span class="number">1</span>].<span class="built_in">float</span>().mean()</span><br><span class="line">    <span class="comment"># 精确率：预测正确的objectness个数占总的正类预测个数的比例</span></span><br><span class="line">    end_points[<span class="string">&#x27;stage1_objectness_recall&#x27;</span>] = (objectness_pred == objectness_label.long())[objectness_label == <span class="number">1</span>].<span class="built_in">float</span>().mean()</span><br><span class="line">    <span class="comment"># 召回率：被预测为正类占所有标注的个数</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss, end_points</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_view_loss</span>(<span class="params">end_points</span>):</span></span><br><span class="line">    criterion = nn.MSELoss(reduction=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">    view_score = end_points[<span class="string">&#x27;view_score&#x27;</span>]				<span class="comment"># (B, Ns, V)</span></span><br><span class="line">    view_label = end_points[<span class="string">&#x27;batch_grasp_view_label&#x27;</span>]	<span class="comment"># (B, Ns, V, A, D)</span></span><br><span class="line">    objectness_label = end_points[<span class="string">&#x27;objectness_label&#x27;</span>]	<span class="comment"># (B, M, 1)</span></span><br><span class="line">    fp2_inds = end_points[<span class="string">&#x27;fp2_inds&#x27;</span>].long()			<span class="comment"># (B, Ns)</span></span><br><span class="line">    V = view_label.size(<span class="number">2</span>)</span><br><span class="line">    objectness_label = torch.gather(objectness_label, <span class="number">1</span>, fp2_inds)	<span class="comment"># (B, Ns, 1)</span></span><br><span class="line"></span><br><span class="line">    objectness_mask = (objectness_label &gt; <span class="number">0</span>)</span><br><span class="line">    objectness_mask = objectness_mask.unsqueeze(-<span class="number">1</span>).repeat(<span class="number">1</span>, <span class="number">1</span>, V)	<span class="comment"># (B, Ns, V)</span></span><br><span class="line">    pos_view_pred_mask = ((view_score &gt;= THRESH_GOOD) &amp; objectness_mask)</span><br><span class="line">    <span class="comment"># 满足这个点附近有物体，并且approaching vector的分数满足阈值</span></span><br><span class="line"></span><br><span class="line">    loss = criterion(view_score, view_label)	<span class="comment">#均方误差</span></span><br><span class="line">    loss = loss[objectness_mask].mean()	<span class="comment"># 只取有objectness的部分，其余的如论文所说，忽略掉</span></span><br><span class="line"></span><br><span class="line">    end_points[<span class="string">&#x27;loss/stage1_view_loss&#x27;</span>] = loss</span><br><span class="line">    end_points[<span class="string">&#x27;stage1_pos_view_pred_count&#x27;</span>] = pos_view_pred_mask.long().<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss, end_points</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_grasp_loss</span>(<span class="params">end_points, use_template_in_training=<span class="literal">True</span></span>):</span></span><br><span class="line">    top_view_inds = end_points[<span class="string">&#x27;grasp_top_view_inds&#x27;</span>] 	<span class="comment"># (B, Ns)</span></span><br><span class="line">    vp_rot = end_points[<span class="string">&#x27;grasp_top_view_rot&#x27;</span>] 			<span class="comment"># (B, Ns, view_factor, 3, 3)</span></span><br><span class="line">    objectness_label = end_points[<span class="string">&#x27;objectness_label&#x27;</span>]</span><br><span class="line">    fp2_inds = end_points[<span class="string">&#x27;fp2_inds&#x27;</span>].long()</span><br><span class="line">    objectness_mask = torch.gather(objectness_label, <span class="number">1</span>, fp2_inds).<span class="built_in">bool</span>() <span class="comment"># (B, Ns)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从数据集中得到的，每个batch的Ns个点，都有A * D个Grasp</span></span><br><span class="line">    batch_grasp_label = end_points[<span class="string">&#x27;batch_grasp_label&#x27;</span>] <span class="comment"># (B, Ns, A, D)</span></span><br><span class="line">    batch_grasp_offset = end_points[<span class="string">&#x27;batch_grasp_offset&#x27;</span>] <span class="comment"># (B, Ns, A, D, 3)</span></span><br><span class="line">    batch_grasp_tolerance = end_points[<span class="string">&#x27;batch_grasp_tolerance&#x27;</span>] <span class="comment"># (B, Ns, A, D)</span></span><br><span class="line">    B, Ns, A, D = batch_grasp_label.size()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 以下这段都是在从数据集中取出对应的GT</span></span><br><span class="line">    top_view_grasp_angles = batch_grasp_offset[:, :, :, :, <span class="number">0</span>] <span class="comment">#(B, Ns, A, D)</span></span><br><span class="line">    top_view_grasp_depths = batch_grasp_offset[:, :, :, :, <span class="number">1</span>] <span class="comment">#(B, Ns, A, D)</span></span><br><span class="line">    top_view_grasp_widths = batch_grasp_offset[:, :, :, :, <span class="number">2</span>] <span class="comment">#(B, Ns, A, D)</span></span><br><span class="line">    <span class="comment"># 对于每个深度，取出对应的angle-bin分数最高的inds，并且取出对应的GT</span></span><br><span class="line">    target_labels_inds = torch.argmax(batch_grasp_label, dim=<span class="number">2</span>, keepdim=<span class="literal">True</span>) <span class="comment"># (B, Ns, 1, D)</span></span><br><span class="line">    target_labels = torch.gather(batch_grasp_label, <span class="number">2</span>, target_labels_inds).squeeze(<span class="number">2</span>) <span class="comment"># (B, Ns, D)</span></span><br><span class="line">    target_angles = torch.gather(top_view_grasp_angles, <span class="number">2</span>, target_labels_inds).squeeze(<span class="number">2</span>) <span class="comment"># (B, Ns, D)</span></span><br><span class="line">    target_depths = torch.gather(top_view_grasp_depths, <span class="number">2</span>, target_labels_inds).squeeze(<span class="number">2</span>) <span class="comment"># (B, Ns, D)</span></span><br><span class="line">    target_widths = torch.gather(top_view_grasp_widths, <span class="number">2</span>, target_labels_inds).squeeze(<span class="number">2</span>) <span class="comment"># (B, Ns, D)</span></span><br><span class="line">    target_tolerance = torch.gather(batch_grasp_tolerance, <span class="number">2</span>, target_labels_inds).squeeze(<span class="number">2</span>) <span class="comment"># (B, Ns, D)</span></span><br><span class="line"></span><br><span class="line">    graspable_mask = (target_labels &gt; THRESH_BAD)</span><br><span class="line">    objectness_mask = objectness_mask.unsqueeze(-<span class="number">1</span>).expand_as(graspable_mask)</span><br><span class="line">    loss_mask = (objectness_mask &amp; graspable_mask).<span class="built_in">float</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1. grasp score loss</span></span><br><span class="line">    target_labels_inds_ = target_labels_inds.transpose(<span class="number">1</span>, <span class="number">2</span>) <span class="comment"># (B, 1, Ns, D)</span></span><br><span class="line">    grasp_score = torch.gather(end_points[<span class="string">&#x27;grasp_score_pred&#x27;</span>], <span class="number">1</span>, target_labels_inds_).squeeze(<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># (B, Ns, D)</span></span><br><span class="line">    grasp_score_loss = huber_loss(grasp_score - target_labels, delta=<span class="number">1.0</span>)</span><br><span class="line">    grasp_score_loss = torch.<span class="built_in">sum</span>(grasp_score_loss * loss_mask) / (loss_mask.<span class="built_in">sum</span>() + <span class="number">1e-6</span>)</span><br><span class="line">    <span class="comment"># 只考虑mask==1的情况</span></span><br><span class="line">    end_points[<span class="string">&#x27;loss/stage2_grasp_score_loss&#x27;</span>] = grasp_score_loss</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. inplane rotation cls loss</span></span><br><span class="line">    target_angles_cls = target_labels_inds.squeeze(<span class="number">2</span>) <span class="comment"># (B, Ns, D)</span></span><br><span class="line">    criterion_grasp_angle_class = nn.CrossEntropyLoss(reduction=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">    grasp_angle_class_score = end_points[<span class="string">&#x27;grasp_angle_cls_pred&#x27;</span>]</span><br><span class="line">    grasp_angle_class_loss = criterion_grasp_angle_class(grasp_angle_class_score, target_angles_cls)</span><br><span class="line">    grasp_angle_class_loss = torch.<span class="built_in">sum</span>(grasp_angle_class_loss * loss_mask) / (loss_mask.<span class="built_in">sum</span>() + <span class="number">1e-6</span>)</span><br><span class="line">    <span class="comment"># 多分类交叉熵</span></span><br><span class="line">    end_points[<span class="string">&#x27;loss/stage2_grasp_angle_class_loss&#x27;</span>] = grasp_angle_class_loss</span><br><span class="line">    grasp_angle_class_pred = torch.argmax(grasp_angle_class_score, <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 得到分数最高的in-place rotation</span></span><br><span class="line">    end_points[<span class="string">&#x27;stage2_grasp_angle_class_acc/0_degree&#x27;</span>] = (grasp_angle_class_pred==target_angles_cls)[loss_mask.<span class="built_in">bool</span>()].<span class="built_in">float</span>().mean()</span><br><span class="line">    acc_mask_15 = ((torch.<span class="built_in">abs</span>(grasp_angle_class_pred-target_angles_cls) &lt;= <span class="number">1</span>) | (torch.<span class="built_in">abs</span>(grasp_angle_class_pred-target_angles_cls) &gt;= A - <span class="number">1</span>))</span><br><span class="line">    end_points[<span class="string">&#x27;stage2_grasp_angle_class_acc/15_degree&#x27;</span>] = acc_mask_15[loss_mask.<span class="built_in">bool</span>()].<span class="built_in">float</span>().mean()</span><br><span class="line">    acc_mask_30 = ((torch.<span class="built_in">abs</span>(grasp_angle_class_pred-target_angles_cls) &lt;= <span class="number">2</span>) | (torch.<span class="built_in">abs</span>(grasp_angle_class_pred-target_angles_cls) &gt;= A - <span class="number">2</span>))</span><br><span class="line">    end_points[<span class="string">&#x27;stage2_grasp_angle_class_acc/30_degree&#x27;</span>] = acc_mask_30[loss_mask.<span class="built_in">bool</span>()].<span class="built_in">float</span>().mean()</span><br><span class="line">	<span class="comment"># 因为一类相差15度，此处就根据分类的具体位置是否相差1个或2个来计算15度/30度的accuracy</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3. width reg loss</span></span><br><span class="line">    grasp_width_pred = torch.gather(end_points[<span class="string">&#x27;grasp_width_pred&#x27;</span>], <span class="number">1</span>, target_labels_inds_).squeeze(<span class="number">1</span>)</span><br><span class="line">    <span class="comment">#  (B, num_angle, Ns, D) =&gt; (B, Ns, D)</span></span><br><span class="line">    grasp_width_loss = huber_loss((grasp_width_pred-target_widths)/GRASP_MAX_WIDTH, delta=<span class="number">1</span>)</span><br><span class="line">    grasp_width_loss = torch.<span class="built_in">sum</span>(grasp_width_loss * loss_mask) / (loss_mask.<span class="built_in">sum</span>() + <span class="number">1e-6</span>)</span><br><span class="line">    <span class="comment"># 对width做回归</span></span><br><span class="line">    end_points[<span class="string">&#x27;loss/stage2_grasp_width_loss&#x27;</span>] = grasp_width_loss</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4. tolerance reg loss</span></span><br><span class="line">    grasp_tolerance_pred = torch.gather(end_points[<span class="string">&#x27;grasp_tolerance_pred&#x27;</span>], <span class="number">1</span>, target_labels_inds_).squeeze(<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># (B, num_angle, Ns, D) =&gt; (B, Ns, D)</span></span><br><span class="line">    grasp_tolerance_loss = huber_loss((grasp_tolerance_pred-target_tolerance)/GRASP_MAX_TOLERANCE, delta=<span class="number">1</span>)</span><br><span class="line">    grasp_tolerance_loss = torch.<span class="built_in">sum</span>(grasp_tolerance_loss * loss_mask) / (loss_mask.<span class="built_in">sum</span>() + <span class="number">1e-6</span>)</span><br><span class="line">    end_points[<span class="string">&#x27;loss/stage2_grasp_tolerance_loss&#x27;</span>] = grasp_tolerance_loss</span><br><span class="line"></span><br><span class="line">    grasp_loss = grasp_score_loss + grasp_angle_class_loss\</span><br><span class="line">                + grasp_width_loss + grasp_tolerance_loss</span><br><span class="line">    <span class="keyword">return</span> grasp_loss, end_points</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">huber_loss</span>(<span class="params">error, delta=<span class="number">1.0</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        error: Torch tensor (d1,d2,...,dk)</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        loss: Torch tensor (d1,d2,...,dk)</span></span><br><span class="line"><span class="string">    x = error = pred - gt or dist(pred,gt)</span></span><br><span class="line"><span class="string">    0.5 * |x|^2                 if |x|&lt;=d</span></span><br><span class="line"><span class="string">    0.5 * d^2 + d * (|x|-d)     if |x|&gt;d</span></span><br><span class="line"><span class="string">    Author: Charles R. Qi</span></span><br><span class="line"><span class="string">    Ref: https://github.com/charlesq34/frustum-pointnets/blob/master/models/model_util.py</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    abs_error = torch.<span class="built_in">abs</span>(error)</span><br><span class="line">    quadratic = torch.clamp(abs_error, <span class="built_in">max</span>=delta)</span><br><span class="line">    linear = (abs_error - quadratic)</span><br><span class="line">    loss = <span class="number">0.5</span> * quadratic**<span class="number">2</span> + delta * linear</span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>



<h1 id="附言"><a href="#附言" class="headerlink" title="附言"></a>附言</h1><p>​    和浩树学长聊了一下，他很明确地指出这其实是一个多分类任务。并且因为论文中提到了使用离散的Bin来代替回归出一个向量的idea，我就继续请教了一下这样做的原因。因为这一点其实在VoteNet中尝试预测物体的6D pose的时候，也是有体现的。他认为回归在方法论上就不太对，因为正常的情况下Valid Approach Vector / Operations 应当是一个分布，而不是回归出来的一个值。多分类对于每个离散的bin预测出一个score，在我的理解下，就是用细粒度的均匀分布去拟合这个我们所希望预测的分布，这样训练效果就会好。听罢，感叹自己科研的路上还有很多路要走…因为各种各样的论文只会告诉你它的优点是什么，真正的硬伤都不会写在论文里。而要把握领域前沿动向，并且做出正确的选择，那就必须要在这种抽象层面上建构出自己稳定的理论体系， 但是我觉得我自己还差了很多这一块的知识积累。真是道阻且长啊。好在，我在努力开发出很多未来可以使用的方法论、视野、论文积累、代码积累等，希望可以在这条路上继续努力！</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>(CVPR2020)GraspNet-1Billion</p><p><a href="https://kami-code.com/blog/2022/01/18/GraspNet-1Billion/">https://kami-code.com/blog/2022/01/18/GraspNet-1Billion/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Kami-code</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2022-01-18</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2022-02-13</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/blog/tags/GraspNet/">GraspNet</a><a class="link-muted mr-2" rel="tag" href="/blog/tags/CVPR/">CVPR</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/blog/2022/01/26/GIGA/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">(RSS2021)GIGA</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/blog/2022/01/17/6D-GraspNet/"><span class="level-item">(ICCV2019)6D-GraspNet</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="SOHUCS" sid="2022/01/18/GraspNet-1Billion/"></div><script charset="utf-8" src="https://changyan.sohu.com/upload/changyan.js"></script><script>window.changyan.api.config({appid: 'cyvI88c19',conf: 'prod_634561f1ec380218934dcf2c12b8b70b'});</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/blog/img/avatar.jpg" alt="Chen Bao"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Chen Bao</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shanghai, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/blog/archives"><p class="title">31</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/blog/categories"><p class="title">0</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/blog/tags"><p class="title">38</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Kami-code" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Kami-code"><i class="fab fa-github"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><!--!--><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-03-22T06:43:39.000Z">2022-03-22</time></p><p class="title"><a href="/blog/2022/03/22/dual_boot/">双系统的配置和安装</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-03-13T08:18:21.000Z">2022-03-13</time></p><p class="title"><a href="/blog/2022/03/13/GraspTTA/">(ICCV2021)Hand-Object Contact Consistency Reasoning for Human Grasps Generation</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-03-02T06:24:03.000Z">2022-03-02</time></p><p class="title"><a href="/blog/2022/03/02/NOCS/">(CVPR2019)NOCS</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-02-20T14:35:48.000Z">2022-02-20</time></p><p class="title"><a href="/blog/2022/02/20/A-SDF/">(ICCV2021)A-SDF</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-02-19T13:44:21.000Z">2022-02-19</time></p><p class="title"><a href="/blog/2022/02/19/akb48/">A Real-World Articulated Object Knowledge Base</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/blog/archives/2022/03/"><span class="level-start"><span class="level-item">March 2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/blog/archives/2022/02/"><span class="level-start"><span class="level-item">February 2022</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/blog/archives/2022/01/"><span class="level-start"><span class="level-item">January 2022</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/blog/archives/2021/12/"><span class="level-start"><span class="level-item">December 2021</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/blog/archives/2021/11/"><span class="level-start"><span class="level-item">November 2021</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/blog/archives/2021/10/"><span class="level-start"><span class="level-item">October 2021</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/blog/tags/Affordance/"><span class="tag">Affordance</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/BCO/"><span class="tag">BCO</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/CHOMP/"><span class="tag">CHOMP</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/CVPR/"><span class="tag">CVPR</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Camera/"><span class="tag">Camera</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Docker/"><span class="tag">Docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/GraspNet/"><span class="tag">GraspNet</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/ICCV/"><span class="tag">ICCV</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/ICRA/"><span class="tag">ICRA</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/IJCAI/"><span class="tag">IJCAI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/IROS/"><span class="tag">IROS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/MongoDB/"><span class="tag">MongoDB</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/MySQL/"><span class="tag">MySQL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Neo4j/"><span class="tag">Neo4j</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/OpenCV/"><span class="tag">OpenCV</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/OpenGL/"><span class="tag">OpenGL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/PointNet/"><span class="tag">PointNet</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/PointNet/"><span class="tag">PointNet++</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Pybind11/"><span class="tag">Pybind11</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Pybullet/"><span class="tag">Pybullet</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/ROS/"><span class="tag">ROS</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/RSS/"><span class="tag">RSS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/SE3353/"><span class="tag">SE3353</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/SOIL/"><span class="tag">SOIL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/ScrewNet/"><span class="tag">ScrewNet</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Search/"><span class="tag">Search</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/VoteNet/"><span class="tag">VoteNet</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/WebService/"><span class="tag">WebService</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/behavior-tree/"><span class="tag">behavior tree</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/compliers/"><span class="tag">compliers</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/deeplearning/"><span class="tag">deeplearning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/ikfast/"><span class="tag">ikfast</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/lab/"><span class="tag">lab</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/mmdection/"><span class="tag">mmdection</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/moveit/"><span class="tag">moveit</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/planning/"><span class="tag">planning</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/pybullet/"><span class="tag">pybullet</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/segmentation/"><span class="tag">segmentation</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/blog/"><img src="/blog/img/logo.svg" alt="Ryan &#039;s website" height="28"></a><span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span><span class="post-meta-divider">|</span><span id="busuanzi_container_site_uv" style="display:none">本站访客数<span id="busuanzi_value_site_uv"></span>人</span><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><p class="is-size-7"><span>&copy; 2023 Kami-code</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/blog/js/column.js"></script><script src="/blog/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/blog/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/blog/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/blog/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/blog/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>