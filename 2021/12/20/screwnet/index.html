<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>(ICRA2021)ScrewNet - Ryan &#039;s website</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Ryan&#039;s blog"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Ryan&#039;s blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="ScrewNet论文阅读和源码分析。"><meta property="og:type" content="blog"><meta property="og:title" content="(ICRA2021)ScrewNet"><meta property="og:url" content="https://kami-code.com/2021/12/20/screwnet/"><meta property="og:site_name" content="Ryan &#039;s website"><meta property="og:description" content="ScrewNet论文阅读和源码分析。"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://kami-code.com/2021/12/20/screwnet/image-20211220104058424.png"><meta property="og:image" content="https://kami-code.com/2021/12/20/screwnet/552c256858584141ab7cd86119dc11a7.png"><meta property="og:image" content="https://kami-code.com/2021/12/20/screwnet/image-20211220154744359.png"><meta property="article:published_time" content="2021-12-20T02:39:49.000Z"><meta property="article:modified_time" content="2022-02-14T15:21:57.856Z"><meta property="article:author" content="Kami-code"><meta property="article:tag" content="ICRA"><meta property="article:tag" content="ScrewNet"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/2021/12/20/screwnet/image-20211220104058424.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://kami-code.com/2021/12/20/screwnet/"},"headline":"(ICRA2021)ScrewNet","image":["https://kami-code.com/2021/12/20/screwnet/image-20211220104058424.png","https://kami-code.com/2021/12/20/screwnet/552c256858584141ab7cd86119dc11a7.png","https://kami-code.com/2021/12/20/screwnet/image-20211220154744359.png"],"datePublished":"2021-12-20T02:39:49.000Z","dateModified":"2022-02-14T15:21:57.856Z","author":{"@type":"Person","name":"Kami-code"},"publisher":{"@type":"Organization","name":"Ryan 's website","logo":{"@type":"ImageObject","url":"https://kami-code.com/img/logo.svg"}},"description":"ScrewNet论文阅读和源码分析。"}</script><link rel="canonical" href="https://kami-code.com/2021/12/20/screwnet/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Ryan &#039;s website" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-12-20T02:39:49.000Z" title="2021/12/20 上午10:39:49">2021-12-20</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-02-14T15:21:57.856Z" title="2022/2/14 下午11:21:57">2022-02-14</time></span><span class="level-item">36 minutes read (About 5376 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">(ICRA2021)ScrewNet</h1><div class="content"><p>ScrewNet论文阅读和源码分析。<span id="more"></span></p>
<h3 id="核心表述"><a href="#核心表述" class="headerlink" title="核心表述"></a>核心表述</h3><p>​    其实ScrewNet的目的很简单，希望从深度图中直接估计出物体的关节模型及其位形信息，而之前的工作都需要引入额外的关节体的纹理信息、或者指定关节体的类型(rigid、revolute、prismatic，helical)。</p>
<p>​    ScrewNet的核心结构如下：</p>
<img src="/2021/12/20/screwnet/image-20211220104058424.png" style="zoom:50%;">

<p>​    对于N帧深度图，每一帧都先使用ResNet-18作为backbone来提取2D图像特征，然后提取出来的N个特征向量传入到LSTM层中计算，然后输出N-1 X 8个相对的Screw Parameter。此处提供一个复习LSTM的<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/9dc9f41f0b29">博客</a>。</p>
<h3 id="Screw-Theory"><a href="#Screw-Theory" class="headerlink" title="Screw Theory"></a>Screw Theory</h3><p>​    这篇文章能中ICRA的点就在于此。“空间中任何一个物体的位移都可以通过绕着一条直线的旋转以及绕着这条线的平行移动解决。”这条线叫做screw axis of displacement $S$。在<a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_37592209/article/details/121016415">普吕克坐标系</a>下，直线可以表示成$(\textbf{l}, \textbf{m})$的形式，并且满足$||\textbf{l}||=1$和$\textbf{l}\cdot\textbf{m}=0$这两个约束条件。其实也很容易理解，在欧式坐标下，我们取直线的一段线段，有端点x和y。我们令<br>$$<br>\textbf{l}=\text{normalize} (y-x) \<br>\textbf{m}=x\times y<br>$$<br>​    这就是普吕克坐标下表示直线的方法。</p>
<img src="/2021/12/20/screwnet/552c256858584141ab7cd86119dc11a7.png" style="zoom:50%;">

<p>​    上图中的$(d,m)$就是我们的$(\textbf{l}, \textbf{m})$。</p>
<p>​    所以ScrewNet就使用了$(\textbf{l}, \textbf{m}, \theta, d)$来表示在SE(3)中的刚体运动。其中$d$是沿着轴的线性平移，而$\theta$是绕着轴的旋转，并且满足$d=h\theta$。</p>
<h3 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h3><p>​    Screw位移包括了两部分：screw轴$S$，以及对应的位形$q_i$。所以ScrewNet希望同时优化如下的多个目标损失：<br>$$<br>L=\lambda_1L_{S_{ori}}+\lambda_2L_{S_{dist}}+\lambda_3L_{S_{cons}}+\lambda_4{L_q}<br>$$<br>​    其中$L_{S_{ori}}$惩罚的是screw轴的偏差，所以通过GT轴和screw轴的角度偏差来计算，而$L_{S_{dist}}$是惩罚的是预测的screw轴和GT轴的空间距离，通过普吕克坐标系下的直线距离来表示。即：</p>
<p>$$<br>d((\textbf{l}_1,\textbf{m}_1),(\textbf{l}_2,\textbf{m}_2))=<br>\begin{cases}<br>0,  &amp; \text{if $\textbf{l}_1$ and $\textbf{l}_2$ intersect} \\<br>||\textbf{l}_1\times(\textbf{m}_1-\textbf{m}_2)||, &amp; \text{else if $\textbf{l}_1$ and $\textbf{l}_2$ are parallel, i.e.$||\textbf{l}_1\times \textbf{l}_2||=0$}  \\<br>\frac{|\textbf{l}_1\cdot \textbf{m}_2+\textbf{l}_2 \cdot \textbf{m}_1|}{||\textbf{l}_1\times \textbf{l}_2||}, &amp; else,\textbf{l}_1\ and\ \textbf{l}_2\ are\ skew\ lines<br>\end{cases}\\<br>L_{S_{dist}}=d((\textbf{l}_{GT},\textbf{m}_{GT}),(\textbf{l}_{pred},\textbf{m}_{pred}))<br>$$<br>​    而$L_{S_{cons}}$强迫其满足预测出来的直线满足普吕克约束$(\textbf{l}\cdot\textbf{m}=0)$和$||\textbf{l}||=1$；$L_q$是位形损失。</p>
<p>​    其中$L_q$可以由两部分组成：旋转误差$L_{\theta}$和平移误差$L_d$，如下计算：<br>$$<br>L_q=\alpha_1L_{\theta}+\alpha_2L_d \\<br>L_{\theta}=I_{3\times3}-R(\theta_{GT},\textbf{l}_{GT})R(\theta_{pred},\textbf{l}_{pred})^T \\<br>L_d=||d_{GT}\cdot\textbf{l}_{GT}-d_{pred}\cdot\textbf{l}_{pred}||<br>$$<br>​    其中的$R(\theta,\textbf{l})$就是沿着轴$\textbf{l}$旋转$\theta$角度的旋转矩阵$R$。之所以不直接对$q_{GT}$和$q_{pred}$施加$L_2$损失是因为这个损失函数的构成确保了其物理的含义，因为这个损失函数是基于旋转矩阵正交的性质而设计的，所以它可以确保学出来的$\theta_{pred}$和$\textbf{l}_{pred}$是满足$R(\theta_{pred},\textbf{l}_{pred})\in SO(3)$。类似的，损失函数$L_d$也计算了沿着两根不同的轴$\textbf{l}_{GT}$和$\textbf{l}_{pred}$的平移误差，如果我们只是计算$d_{GT}$和$d_{pred}$的范数的话，就等于我们默认了它们是沿着同一个轴平移的，这就不合理。</p>
<p>​    综上所述，我们Loss函数的选取遵循了我们所提出的Screw理论。</p>
<h3 id="打标签方法"><a href="#打标签方法" class="headerlink" title="打标签方法"></a>打标签方法</h3><p>​    ScrewNet的训练集包括了一系列的深度图像，并且需要有对应的screw displacement。使用Mujoco来渲染仿真中的关节体并且记录深度图像。使用了<a target="_blank" rel="noopener" href="http://proceedings.mlr.press/v100/abbatematteo20a/abbatematteo20a.pdf">数据集</a>中的柜子、抽屉、微波炉、烤箱等。</p>
<p>​    为了创建screw displacement标签，我们考虑$o_i$作为基物体，然后我们计算后面的$o_j$相对于基物体的相对screw displacement。具体来说，就是给定一个N帧图片的视频流$I_{1:N}$，我们首先选定视频的第一帧是物体的基础位姿，然后计算出n-1帧的相对的screw displacement。</p>
<img src="/2021/12/20/screwnet/image-20211220154744359.png" style="zoom:50%;">

<p>​    也就是我们有相对于坐标系$F_{O_j^1}$的n-1个位移了，我们可以通过在普吕克坐标下做变换把这n-1个相对位移全部转换到相对于基坐标轴$O_i$下。具体的普吕克坐标系下的变换形式可以参考原文。</p>
<h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><h4 id="1-models-py"><a href="#1-models-py" class="headerlink" title="1.models.py"></a>1.models.py</h4><p>​    在<a target="_blank" rel="noopener" href="https://github.com/Pearl-UTexas/ScrewNet">代码</a>中，ScrewNet提供了三个模型：ScrewNet、ScrewNet_2imgs、ScrewNet_NoLSTM，在实际训练和测试中，和数据集的对应关系如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> args.model_type == <span class="string">&#x27;2imgs&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Testing Model: ScrewNet_2imgs&quot;</span>)</span><br><span class="line">    best_model = ScrewNet_2imgs(n_output=<span class="number">8</span>)</span><br><span class="line">    testset = RigidTransformDataset(args.ntest, args.test_dir)</span><br><span class="line"><span class="keyword">elif</span> args.model_type == <span class="string">&#x27;noLSTM&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Testing Model: ScrewNet_noLSTM&quot;</span>)</span><br><span class="line">    best_model = ScrewNet_NoLSTM(seq_len=<span class="number">16</span>, fc_replace_lstm_dim=<span class="number">1000</span>, n_output=<span class="number">8</span>)</span><br><span class="line">    testset = ArticulationDataset(args.ntest, args.test_dir)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Testing ScrewNet&quot;</span>)</span><br><span class="line">    best_model = ScrewNet(lstm_hidden_dim=<span class="number">1000</span>, n_lstm_hidden_layers=<span class="number">1</span>, n_output=<span class="number">8</span>)</span><br><span class="line">    testset = ArticulationDataset(args.ntest, args.test_dir)</span><br></pre></td></tr></table></figure>

<p>​    其中ScrewNet_2imgs似乎是一个降级版本，我们先从这个模型的源码开始读起：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ScrewNet_2imgs</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_output=<span class="number">8</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(ScrewNet_2imgs, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.fc_mlp_dim_1 = <span class="number">2000</span></span><br><span class="line">        self.fc_mlp_dim_2 = <span class="number">512</span></span><br><span class="line">        self.fc_mlp_dim_3 = <span class="number">256</span></span><br><span class="line">        self.n_output = n_output</span><br><span class="line"></span><br><span class="line">        self.resnet = models.resnet18()</span><br><span class="line">        self.bn_res_1 = nn.BatchNorm1d(<span class="number">1000</span>, momentum=<span class="number">0.01</span>)  <span class="comment">#需要归一化的维度为1000</span></span><br><span class="line"></span><br><span class="line">        self.fc_mlp_1 = nn.Linear(self.fc_mlp_dim_1, self.fc_mlp_dim_1)</span><br><span class="line">        self.bn_mlp_1 = nn.BatchNorm1d(self.fc_mlp_dim_1, momentum=<span class="number">0.01</span>)</span><br><span class="line">        self.fc_mlp_2 = nn.Linear(self.fc_mlp_dim_1, self.fc_mlp_dim_2)</span><br><span class="line">        self.bn_mlp_2 = nn.BatchNorm1d(self.fc_mlp_dim_2, momentum=<span class="number">0.01</span>)</span><br><span class="line">        self.fc_mlp_3 = nn.Linear(self.fc_mlp_dim_2, self.fc_mlp_dim_3)</span><br><span class="line">        self.bn_mlp_3 = nn.BatchNorm1d(self.fc_mlp_dim_3, momentum=<span class="number">0.01</span>)</span><br><span class="line">        self.fc_mlp_4 = nn.Linear(self.fc_mlp_dim_3, self.n_output)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, X_3d</span>):</span></span><br><span class="line">        <span class="comment"># X shape: Batch x Sequence x 3 Channels x img_dims</span></span><br><span class="line">        <span class="comment"># Run resnet sequentially on the data to generate embedding sequence</span></span><br><span class="line">        cnn_embed_seq = []</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(X_3d.size(<span class="number">1</span>)):	<span class="comment">#从第一帧开始枚举</span></span><br><span class="line">            x = self.resnet(X_3d[:, t, :, :, :]) <span class="comment">#resnet的输入B * 1 * 3 * W * H</span></span><br><span class="line">            x = x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)			<span class="comment">#拉伸为B * vector_size(每一个vector为CNN隐变量)</span></span><br><span class="line">            x = self.bn_res_1(x)				<span class="comment">#归一化为B * 1000</span></span><br><span class="line">            cnn_embed_seq.append(x)</span><br><span class="line">		</span><br><span class="line">        <span class="comment"># 此时我们得到了cnn_embed_seq是大小为N的一个list，其中每个元素为B * 1000的格式</span></span><br><span class="line">        <span class="comment"># 首先我们把它变为torch.tensor，并且交换sample dim和time dim</span></span><br><span class="line">        cnn_embed_seq = torch.stack(cnn_embed_seq, dim=<span class="number">0</span>).transpose_(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 此时我们有cnn_embed_seq = (B * N * 1000)</span></span><br><span class="line">        <span class="comment"># 因为在transpose后，虽然tensor的shape改变了，但是它在内存中的存储位置并没有改变，如果我们直接调用view会出错，所以我们需要先做.contiguous()，然后再使用view</span></span><br><span class="line">        x_rnn = cnn_embed_seq.contiguous().view(-<span class="number">1</span>, self.fc_mlp_dim_1)</span><br><span class="line">		<span class="comment"># 注意到我们此时view成了(B * 2000)，所以我们可以反推原先输入的N=2，所以这个模型的dataset都是2帧的视频</span></span><br><span class="line">        <span class="comment"># FC layers</span></span><br><span class="line">        x_rnn = self.fc_mlp_1(x_rnn)  	<span class="comment"># B * 2000 =&gt; B * 2000</span></span><br><span class="line">        x_rnn = F.relu(x_rnn)</span><br><span class="line">        x_rnn = self.bn_mlp_1(x_rnn)</span><br><span class="line">        x_rnn = self.fc_mlp_2(x_rnn)	<span class="comment"># B * 2000 =&gt; B * 512</span></span><br><span class="line">        x_rnn = F.relu(x_rnn)</span><br><span class="line">        x_rnn = self.bn_mlp_2(x_rnn)	</span><br><span class="line">        x_rnn = self.fc_mlp_3(x_rnn)	<span class="comment"># B * 512 =&gt; B * 256</span></span><br><span class="line">        x_rnn = F.relu(x_rnn)</span><br><span class="line">        x_rnn = self.bn_mlp_3(x_rnn)</span><br><span class="line">        x_rnn = self.fc_mlp_4(x_rnn)	<span class="comment"># B * 256 =&gt; B * 8（其中8维就是screw parameter)</span></span><br><span class="line">        <span class="keyword">return</span> x_rnn.view(X_3d.size(<span class="number">0</span>), -<span class="number">1</span>)	<span class="comment">#返回 B * 8</span></span><br></pre></td></tr></table></figure>

<p>​    其中的models.resnet18()其实是torchvision.models.resnet.py中帮我们实现好的resnet，我们可以单纯地认为输入B * 3 * W * H，输出一个B * 1000的ResNet特征。</p>
<p>​    接下来是No_LSTM版本的ScrewNet：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ScrewNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, lstm_hidden_dim=<span class="number">1000</span>, n_lstm_hidden_layers=<span class="number">1</span>, drop_p=<span class="number">0.5</span>, n_output=<span class="number">8</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(ScrewNet, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.fc_res_dim_1 = <span class="number">512</span></span><br><span class="line">        self.lstm_input_dim = <span class="number">1000</span></span><br><span class="line">        self.lstm_hidden_dim = lstm_hidden_dim</span><br><span class="line">        self.n_lstm_hidden_layers = n_lstm_hidden_layers</span><br><span class="line">        self.fc_lstm_dim_1 = <span class="number">256</span></span><br><span class="line">        self.fc_lstm_dim_2 = <span class="number">128</span></span><br><span class="line">        self.n_output = n_output</span><br><span class="line">        self.drop_p = drop_p</span><br><span class="line"></span><br><span class="line">        self.resnet = models.resnet18()</span><br><span class="line">        self.fc_res_1 = nn.Linear(self.lstm_input_dim, self.fc_res_dim_1)</span><br><span class="line">        self.bn_res_1 = nn.BatchNorm1d(self.fc_res_dim_1, momentum=<span class="number">0.01</span>)</span><br><span class="line">        self.fc_res_2 = nn.Linear(self.fc_res_dim_1, self.lstm_input_dim)</span><br><span class="line"></span><br><span class="line">        self.LSTM = nn.LSTM(</span><br><span class="line">            input_size=self.lstm_input_dim,</span><br><span class="line">            hidden_size=self.lstm_hidden_dim,</span><br><span class="line">            num_layers=self.n_lstm_hidden_layers,</span><br><span class="line">            batch_first=<span class="literal">True</span>,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.fc_lstm_1 = nn.Linear(self.lstm_hidden_dim, self.fc_lstm_dim_1)</span><br><span class="line">        self.bn_lstm_1 = nn.BatchNorm1d(self.fc_lstm_dim_1, momentum=<span class="number">0.01</span>)</span><br><span class="line">        self.fc_lstm_2 = nn.Linear(self.fc_lstm_dim_1, self.fc_lstm_dim_2)</span><br><span class="line">        self.bn_lstm_2 = nn.BatchNorm1d(self.fc_lstm_dim_2, momentum=<span class="number">0.01</span>)</span><br><span class="line">        self.dropout_layer1 = nn.Dropout(p=self.drop_p)</span><br><span class="line">        self.fc_lstm_3 = nn.Linear(self.fc_lstm_dim_2, self.n_output)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, X_3d</span>):</span></span><br><span class="line">        <span class="comment"># 输入的大小 B * N * 3 * W * H</span></span><br><span class="line">        cnn_embed_seq = []</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(X_3d.size(<span class="number">1</span>)):	<span class="comment">#枚举N帧</span></span><br><span class="line">            x = self.resnet(X_3d[:, t, :, :, :])	<span class="comment"># B * 1 * 1000</span></span><br><span class="line">            x = x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)				<span class="comment"># B * 1000</span></span><br><span class="line">            x = self.bn_res_1(self.fc_res_1(x))		<span class="comment"># B * 1000 =&gt; B * 512</span></span><br><span class="line">            x = F.relu(x)</span><br><span class="line">            x = self.fc_res_2(x)					<span class="comment"># B * 512 =&gt; B * 1000</span></span><br><span class="line">            cnn_embed_seq.append(x)</span><br><span class="line">            </span><br><span class="line">        cnn_embed_seq = torch.stack(cnn_embed_seq, dim=<span class="number">0</span>).transpose_(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 此时我们有cnn_embed_seq = (B * N * 1000)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 为了提高内存的利用率和效率，调用flatten_parameters让parameter的数据存放成contiguous chunk(连续的块)。类似我们调用tensor.contiguous</span></span><br><span class="line">        self.LSTM.flatten_parameters()</span><br><span class="line"></span><br><span class="line">        RNN_out, (h_n, h_c) = self.LSTM(cnn_embed_seq, <span class="literal">None</span>)</span><br><span class="line">        <span class="comment"># h_c shape (n_layers, B, hidden_size)，默认值为(1, B, 1000)</span></span><br><span class="line">        <span class="comment"># h_n shape (n_layers, B, hidden_size)，默认值为(1, B, 1000)</span></span><br><span class="line">        <span class="comment"># RNN_out = (B * N * 1000)</span></span><br><span class="line">        <span class="comment"># None represents zero initial hidden state</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># FC layers</span></span><br><span class="line">        x_rnn = RNN_out.contiguous().view(-<span class="number">1</span>, self.lstm_hidden_dim)  <span class="comment"># BN * 1000</span></span><br><span class="line">        x_rnn = self.bn_lstm_1(self.fc_lstm_1(x_rnn))	<span class="comment"># BN * 1000 =&gt; BN * 256</span></span><br><span class="line">        x_rnn = F.relu(x_rnn)</span><br><span class="line">        x_rnn = self.bn_lstm_2(self.fc_lstm_2(x_rnn))	<span class="comment"># BN * 256 =&gt; BN * 128</span></span><br><span class="line">        x_rnn = F.relu(x_rnn)</span><br><span class="line">        x_rnn = self.fc_lstm_3(x_rnn)					<span class="comment"># BN * 8</span></span><br><span class="line">        <span class="keyword">return</span> x_rnn.view(X_3d.size(<span class="number">0</span>), -<span class="number">1</span>)				<span class="comment"># return B * 8N</span></span><br></pre></td></tr></table></figure>

<p>​    这里涉及到LSTM的输入和输出，可以参考<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html">官网上的参数介绍</a>。注意到最后的全连接层的维度变化，最后之所以预测B * 8N，是因为每个样本都有N帧，我们需要预测出每一帧的关节体参数，至于为什么不是$B \times N \times8$，这倒不是很重要，反正在back propagation的时候我们只需要准确地实现loss function，都能回归出来。</p>
<p>​    代码中还提供了一个no_lstm版本，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ScrewNet_NoLSTM</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, seq_len=<span class="number">16</span>, fc_replace_lstm_dim=<span class="number">1000</span>, n_output=<span class="number">8</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(ScrewNet_NoLSTM, self).__init__()</span><br><span class="line">        self.fc_replace_lstm_seq_dim = fc_replace_lstm_dim * seq_len</span><br><span class="line">        ...</span><br><span class="line">        self.fc_replace_lstm = nn.Linear(self.fc_replace_lstm_seq_dim, self.fc_replace_lstm_seq_dim)</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, X_3d</span>):</span></span><br><span class="line">        ...</span><br><span class="line">		<span class="comment"># FC replacing LSTM layer</span></span><br><span class="line">    	<span class="comment"># cnn_embed_seq = (B * N * 1000)</span></span><br><span class="line">        cnn_embed_seq = cnn_embed_seq.contiguous().view(cnn_embed_seq.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># (B * N * 1000) =&gt; (B * 1000N)</span></span><br><span class="line">        x_rnn = F.relu(self.fc_replace_lstm(cnn_embed_seq))	<span class="comment">#(B * 1000N) =&gt; (B * 1000N)</span></span><br><span class="line">        x_rnn = x_rnn.view(-<span class="number">1</span>, self.fc_replace_lstm_dim)	<span class="comment">#(BN * 1000)</span></span><br><span class="line">        <span class="comment">#后面就继续连接FC层和上面一模一样了</span></span><br><span class="line">        ...</span><br></pre></td></tr></table></figure>

<h3 id="loss-py"><a href="#loss-py" class="headerlink" title="loss.py"></a>loss.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">articulation_lstm_loss_spatial_distance</span>(<span class="params">pred, target, wt_on_ortho=<span class="number">1.</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; Based on Spatial distance. Please refer to the paper for more details.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    pred = pred.view(pred.size(<span class="number">0</span>), -<span class="number">1</span>, <span class="number">8</span>)[:, <span class="number">1</span>:, :]  <span class="comment"># We don&#x27;t need the first row as it is for single image</span></span><br><span class="line">	<span class="comment"># (B, N - 1, 8)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Spatial Distance loss，计算的是轴角度的误差以及轴平移的误差</span></span><br><span class="line">    dist_err = orientation_difference_bw_plucker_lines(target, pred) ** <span class="number">2</span> + \</span><br><span class="line">               <span class="number">2.</span> * distance_bw_plucker_lines(target, pred) ** <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Configuration Loss，也就是theta和d的误差</span></span><br><span class="line">    conf_err = theta_config_error(target, pred) ** <span class="number">2</span> + d_config_error(target, pred) ** <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    err = dist_err + conf_err</span><br><span class="line">    loss = torch.mean(err)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Ensure l_hat has norm 1.</span></span><br><span class="line">    <span class="comment"># 单位向量约束</span></span><br><span class="line">    loss += torch.mean((torch.norm(pred[:, :, :<span class="number">3</span>], dim=-<span class="number">1</span>) - <span class="number">1.</span>) ** <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Ensure orthogonality between l_hat and m</span></span><br><span class="line">    <span class="comment"># l和m的正交约束</span></span><br><span class="line">    loss += wt_on_ortho * torch.mean(torch.<span class="built_in">abs</span>(torch.<span class="built_in">sum</span>(torch.mul(pred[:, :, :<span class="number">3</span>], pred[:, :, <span class="number">3</span>:<span class="number">6</span>]), dim=-<span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> torch.isnan(loss):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;target: Min: &#123;&#125;,  Max&#123;&#125;&quot;</span>.<span class="built_in">format</span>(target.<span class="built_in">min</span>(), target.<span class="built_in">max</span>()))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Prediction: Min: &#123;&#125;,  Max&#123;&#125;&quot;</span>.<span class="built_in">format</span>(pred.<span class="built_in">min</span>(), pred.<span class="built_in">max</span>()))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;L2 error: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(torch.mean((target - pred) ** <span class="number">2</span>)))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Distance loss:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(torch.mean(orientation_difference_bw_plucker_lines(target, pred) ** <span class="number">2</span>)))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Orientation loss:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(torch.mean(distance_bw_plucker_lines(target, pred) ** <span class="number">2</span>)))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Configuration loss:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(torch.mean(conf_err)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distance_bw_plucker_lines</span>(<span class="params">target, prediction, eps=<span class="number">1e-10</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; Input shapes Tensors: Batch X #Images X 8</span></span><br><span class="line"><span class="string">    # Based on formula from Plücker Coordinates for Lines in the Space by Prof. Yan-bin Jia</span></span><br><span class="line"><span class="string">    # Verified by https://keisan.casio.com/exec/system/1223531414</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    norm_cross_prod = torch.norm(torch.cross(target[:, :, :<span class="number">3</span>], prediction[:, :, :<span class="number">3</span>], dim=-<span class="number">1</span>), dim=-<span class="number">1</span>)</span><br><span class="line">    dist = torch.zeros_like(norm_cross_prod)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Checking for Parallel Lines</span></span><br><span class="line">    <span class="keyword">if</span> torch.<span class="built_in">any</span>(norm_cross_prod &lt;= eps):</span><br><span class="line">        zero_idxs = (norm_cross_prod &lt;= eps).nonzero(as_tuple=<span class="literal">True</span>)</span><br><span class="line">        scales = torch.norm(prediction[zero_idxs][:, :<span class="number">3</span>], dim=-<span class="number">1</span>) / torch.norm(target[zero_idxs][:, :<span class="number">3</span>], dim=-<span class="number">1</span>) + eps</span><br><span class="line">        dist[zero_idxs] = torch.norm(torch.cross(target[zero_idxs][:, :<span class="number">3</span>], (</span><br><span class="line">                target[zero_idxs][:, <span class="number">3</span>:<span class="number">6</span>] - prediction[zero_idxs][:, <span class="number">3</span>:<span class="number">6</span>] / scales.unsqueeze(-<span class="number">1</span>))), dim=-<span class="number">1</span>) / (</span><br><span class="line">                                  torch.mul(target[zero_idxs][:, :<span class="number">3</span>], target[zero_idxs][:, :<span class="number">3</span>]).<span class="built_in">sum</span>(dim=-<span class="number">1</span>) + eps)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Skew Lines: Non zero cross product</span></span><br><span class="line">    nonzero_idxs = (norm_cross_prod &gt; eps).nonzero(as_tuple=<span class="literal">True</span>)</span><br><span class="line">    dist[nonzero_idxs] = torch.<span class="built_in">abs</span>(</span><br><span class="line">        torch.mul(target[nonzero_idxs][:, :<span class="number">3</span>], prediction[nonzero_idxs][:, <span class="number">3</span>:<span class="number">6</span>]).<span class="built_in">sum</span>(dim=-<span class="number">1</span>) + torch.mul(</span><br><span class="line">            target[nonzero_idxs][:, <span class="number">3</span>:<span class="number">6</span>], prediction[nonzero_idxs][:, :<span class="number">3</span>]).<span class="built_in">sum</span>(dim=-<span class="number">1</span>)) / (</span><br><span class="line">                                 norm_cross_prod[nonzero_idxs] + eps)</span><br><span class="line">    <span class="keyword">return</span> dist</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">orientation_difference_bw_plucker_lines</span>(<span class="params">target, prediction, eps=<span class="number">1e-6</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; Input shapes Tensors: (B, N, 8)</span></span><br><span class="line"><span class="string">    range of arccos ins [0, pi)&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> torch.acos(torch.clamp(torch.mul(target[:, :, :<span class="number">3</span>], prediction[:, :, :<span class="number">3</span>]).<span class="built_in">sum</span>(dim=-<span class="number">1</span>) / </span><br><span class="line">    (torch.norm(target[:, :, :<span class="number">3</span>], dim=-<span class="number">1</span>) * torch.norm(prediction[:, :, :<span class="number">3</span>], dim=-<span class="number">1</span>) + eps), <span class="built_in">min</span>=-<span class="number">1</span>, <span class="built_in">max</span>=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">theta_config_error</span>(<span class="params">target, prediction</span>):</span></span><br><span class="line">    <span class="comment"># theta的loss</span></span><br><span class="line">    rot_tar = angle_axis_to_rotation_matrix(target[:, :, :<span class="number">3</span>], target[:, :, <span class="number">6</span>]).view(-<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">    rot_pred = angle_axis_to_rotation_matrix(prediction[:, :, :<span class="number">3</span>], prediction[:, :, <span class="number">6</span>]).view(-<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">    I_ = torch.eye(<span class="number">3</span>).reshape((<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">    I_ = I_.repeat(rot_tar.size(<span class="number">0</span>), <span class="number">1</span>, <span class="number">1</span>).to(target.device)</span><br><span class="line">    <span class="keyword">return</span> torch.norm(I_ - torch.bmm(rot_pred, rot_tar.transpose(<span class="number">1</span>, <span class="number">2</span>)), dim=(<span class="number">1</span>, <span class="number">2</span>), p=<span class="number">2</span>).view(target.shape[:<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">d_config_error</span>(<span class="params">target, prediction</span>):</span></span><br><span class="line">    tar_d = target[:, :, <span class="number">7</span>].unsqueeze(-<span class="number">1</span>)</span><br><span class="line">    pred_d = prediction[:, :, <span class="number">7</span>].unsqueeze(-<span class="number">1</span>)</span><br><span class="line">    tar_d = target[:, :, :<span class="number">3</span>] * tar_d</span><br><span class="line">    pred_d = prediction[:, :, :<span class="number">3</span>] * pred_d</span><br><span class="line">    <span class="keyword">return</span> (tar_d - pred_d).norm(dim=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure>



<h4 id="2-dataset-py"><a href="#2-dataset-py" class="headerlink" title="2.dataset.py"></a>2.dataset.py</h4><p>​    我们先从简单的两张图片的数据集RigidTransformDataset入手，注意到数据集只需要override __len__和 __getitem__。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Data loader class for the 2-imgs ablated version </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RigidTransformDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="params"><span class="function">                 ntrain,</span></span></span><br><span class="line"><span class="params"><span class="function">                 root_dir,</span></span></span><br><span class="line"><span class="params"><span class="function">                 n_dof=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 norm_factor=<span class="number">1.</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 transform=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(RigidTransformDataset, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.root_dir = root_dir</span><br><span class="line">        self.labels_data = <span class="literal">None</span></span><br><span class="line">        self.length = ntrain</span><br><span class="line">        self.n_dof = n_dof</span><br><span class="line">        self.normalization_factor = norm_factor</span><br><span class="line">        self.transform = transform</span><br><span class="line">        self.augmentation_factor = <span class="number">15</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.length</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, idx, imgs_per_object=<span class="number">16</span></span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.labels_data <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            self.labels_data = h5py.File(os.path.join(self.root_dir, <span class="string">&#x27;complete_data.hdf5&#x27;</span>), <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        obj_idx = <span class="built_in">int</span>(idx / self.augmentation_factor)</span><br><span class="line">        obj_data_idx = idx % self.augmentation_factor + <span class="number">1</span></span><br><span class="line">        obj_data = self.labels_data[<span class="string">&#x27;obj_&#x27;</span> + <span class="built_in">str</span>(obj_idx).zfill(<span class="number">6</span>)]	<span class="comment">#编号补齐0到6位</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Load depth image</span></span><br><span class="line">        depth_imgs = torch.tensor([obj_data[<span class="string">&#x27;depth_imgs&#x27;</span>][<span class="number">0</span>],</span><br><span class="line">                                   obj_data[<span class="string">&#x27;depth_imgs&#x27;</span>][obj_data_idx]])	<span class="comment">#只取开始和最后的两张图片</span></span><br><span class="line">        <span class="comment">#此时为 N * W * H</span></span><br><span class="line">        depth_imgs.unsqueeze_(<span class="number">1</span>).<span class="built_in">float</span>()	<span class="comment">#使用unsqueeze_添加一维，变成 N * 1 * W * H</span></span><br><span class="line">        depth_imgs = torch.cat((depth_imgs, depth_imgs, depth_imgs), dim=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 深度通道复制三份，变成N * 3 * W * H（这真的会有用吗???）</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># # Load labels</span></span><br><span class="line">        pt1 = obj_data[<span class="string">&#x27;moving_frame_in_world&#x27;</span>][<span class="number">0</span>, :]	<span class="comment"># 世界系下的四元数1</span></span><br><span class="line">        pt2 = obj_data[<span class="string">&#x27;moving_frame_in_world&#x27;</span>][obj_data_idx, :]	<span class="comment"># 世界西夏的四元数2</span></span><br><span class="line">        pt1_T_pt2 = change_frames(pt1, pt2) <span class="comment">#计算出相对pose</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Object pose in world</span></span><br><span class="line">        obj_pose_in_world = np.array(obj_data[<span class="string">&#x27;embedding_and_params&#x27;</span>])[-<span class="number">7</span>:]  <span class="comment"># obj_pose, obj_quat_wxyz</span></span><br><span class="line">        obj_T_pt1 = change_frames(obj_pose_in_world, pt1)	<span class="comment">#也就是论文中提到的向着base object frame转换</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 用screw参数创建标签，label := &lt;l_hat, m, theta, d&gt; = &lt;3, 3, 1, 1&gt;</span></span><br><span class="line">        l_hat, m, theta, d = transform_to_screw(translation=pt1_T_pt2[:<span class="number">3</span>],</span><br><span class="line">                                                quat_in_wxyz=pt1_T_pt2[<span class="number">3</span>:])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Convert line in object_local_coordinates</span></span><br><span class="line">        new_l = transform_plucker_line(np.concatenate((l_hat, m)), trans=obj_T_pt1[:<span class="number">3</span>], quat=obj_T_pt1[<span class="number">3</span>:])</span><br><span class="line">        label = np.concatenate((new_l, [theta], [d]))  <span class="comment"># This defines frames wrt pt 1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Normalize labels</span></span><br><span class="line">        label[<span class="number">3</span>:<span class="number">6</span>] /= self.normalization_factor</span><br><span class="line">        <span class="comment"># Scaling m appropriately</span></span><br><span class="line"></span><br><span class="line">        label = torch.from_numpy(label).<span class="built_in">float</span>()</span><br><span class="line">        sample = &#123;<span class="string">&#x27;depth&#x27;</span>: depth_imgs,</span><br><span class="line">                  <span class="string">&#x27;label&#x27;</span>: label&#125;	<span class="comment">#最终一个GT以dict的形式打包传出</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> sample</span><br></pre></td></tr></table></figure>

<p>​    多张图片的其实就大差不差了，不过里面有一个细节我们需要深究一下。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ArticulationDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, idx</span>):</span></span><br><span class="line">        ...</span><br><span class="line">        pt1 = moving_body_poses[<span class="number">0</span>, :]  <span class="comment"># Fixed common reference frame</span></span><br><span class="line">		<span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(moving_body_poses) - <span class="number">1</span>):</span><br><span class="line">            pt2 = moving_body_poses[i + <span class="number">1</span>, :]</span><br><span class="line">            pt1_T_pt2 = change_frames(pt1, pt2)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Generating labels in screw notation: label := &lt;l_hat, m, theta, d&gt; = &lt;3, 3, 1, 1&gt;</span></span><br><span class="line">            l_hat, m, theta, d = transform_to_screw(translation=pt1_T_pt2[:<span class="number">3</span>],</span><br><span class="line">                                                    quat_in_wxyz=pt1_T_pt2[<span class="number">3</span>:])</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Convert line in object_local_coordinates</span></span><br><span class="line">            new_l = transform_plucker_line(np.concatenate((l_hat, m)), trans=obj_T_pt1[:<span class="number">3</span>], quat=obj_T_pt1[<span class="number">3</span>:])</span><br><span class="line">            label[i, :] = np.concatenate((new_l, [theta], [d]))  <span class="comment"># This defines frames wrt pt 1</span></span><br><span class="line">            </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transform_to_screw</span>(<span class="params">translation, quat_in_wxyz, tol=<span class="number">1e-6</span></span>):</span></span><br><span class="line">    dq = dq3d.dualquat(dq3d.quat(quat_as_xyzw(quat_in_wxyz)), translation)</span><br><span class="line">    screw = dual_quaternion_to_screw(dq, tol)</span><br><span class="line">    <span class="keyword">return</span> screw</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dual_quaternion_to_screw</span>(<span class="params">dq, tol=<span class="number">1e-6</span></span>):</span></span><br><span class="line">    l_hat, theta = tf3d.quaternions.quat2axangle(np.array([dq.real.w, dq.real.x, dq.real.y, dq.real.z]))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> theta &lt; tol <span class="keyword">or</span> <span class="built_in">abs</span>(theta - np.pi) &lt; tol:</span><br><span class="line">        t_vec = dq.translation()</span><br><span class="line">        l_hat = t_vec / (np.linalg.norm(t_vec) + <span class="number">1e-10</span>)</span><br><span class="line">        theta = tol  <span class="comment"># This makes sure that tan(theta) is defined</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        t_vec = (<span class="number">2</span> * tf3d.quaternions.qmult(dq.dual.data, tf3d.quaternions.qconjugate(dq.real.data)))[</span><br><span class="line">                <span class="number">1</span>:]  <span class="comment"># taking xyz from wxyz</span></span><br><span class="line"></span><br><span class="line">    d = t_vec.dot(l_hat)</span><br><span class="line">    m = (<span class="number">1</span> / <span class="number">2</span>) * (np.cross(t_vec, l_hat) + ((t_vec - d * l_hat) / np.tan(theta / <span class="number">2</span>)))</span><br><span class="line">    <span class="keyword">return</span> l_hat, m, theta, d</span><br></pre></td></tr></table></figure>

<p>​    只有理解了transform_to_screw这个函数在做什么，我们才真正摸索到了Screw Theory的实质。主要可以参考<a target="_blank" rel="noopener" href="https://faculty.sites.iastate.edu/jia/files/inline-files/dual-quaternion.pdf">这篇文献</a>。总体逻辑就是四元数可以表示三维旋转，而对偶四元数可以同时表示三维旋转和平移，所以使用对偶四元数来表示Screw Parameter就是很合理的事情，满足以下推导：</p>
<p>​    空间任意刚体运动，可分解为刚体上某一点的平移，以及绕经过此点的旋转轴的转动，我们令这个点为连体基坐标原点，我们记作$R$和$t$，旋转矩阵$R$对应的四元数为$p$，由$R$和$t$可以计算出对偶四元数$q$。根据Chasles theorem(Screw theory，沙勒定理)我们又知道：空间任意刚体运动，均可看作有限螺旋运动，即均可表示为绕一轴的旋转和沿该轴的平移，参数可以记为$(\textbf{l},\textbf{m}, \theta, d)$。</p>
<p>​    首先，四元数$p$转化为轴角表达$p=(cos(\frac{\theta}{2}),\textbf{l}sin(\frac{\theta}{2}))$就可以直接得到$\textbf{l}$和$\theta$，参数物理意义完全相同。其余参数满足下式：<br>$$<br>d=\textbf{t}\cdot\textbf{l}=(2qp^*)\cdot\textbf{l} \\<br>m=\frac{1}{2}(\textbf{t}\times\textbf{l}+(\textbf{t}-d\textbf{l})\cot\frac{\theta}{2})<br>$$</p>
<h4 id="3-train-model-py"><a href="#3-train-model-py" class="headerlink" title="3.train_model.py"></a>3.train_model.py</h4><p>​    里面涉及到三种不同的模型的定义，封装地也很好，总体逻辑还是非常简单易懂的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">trainset = ...</span><br><span class="line">testset  = ...</span><br><span class="line">loss_fn = ...</span><br><span class="line">network = ...</span><br><span class="line">testloader = torch.utils.data.DataLoader(testset, batch_size=args.batch,</span><br><span class="line">                                         shuffle=<span class="literal">True</span>, num_workers=args.nwork,</span><br><span class="line">                                         pin_memory=<span class="literal">True</span>)</span><br><span class="line">trainloader = torch.utils.data.DataLoader(trainset, batch_size=args.batch,</span><br><span class="line">                                          shuffle=<span class="literal">True</span>, num_workers=args.nwork,</span><br><span class="line">                                          pin_memory=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># Load Saved weights</span></span><br><span class="line"><span class="keyword">if</span> args.load_wts:</span><br><span class="line">    network.load_state_dict(torch.load(args.wts_dir + args.prior_wts + <span class="string">&#x27;.net&#x27;</span>))</span><br><span class="line"><span class="comment"># setup trainer</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    device = torch.device(args.device)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    device = torch.device(<span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">optimizer = torch.optim.Adam(network.parameters(),</span><br><span class="line">                             lr=args.learning_rate,</span><br><span class="line">                             weight_decay=<span class="number">1e-2</span>)</span><br><span class="line">scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=lr_schedule, gamma=lr_gamma)</span><br><span class="line">trainer = ModelTrainer(model=network,</span><br><span class="line">                       train_loader=trainloader,</span><br><span class="line">                       test_loader=testloader,</span><br><span class="line">                       optimizer=optimizer,</span><br><span class="line">                       scheduler=scheduler,</span><br><span class="line">                       criterion=loss_fn,</span><br><span class="line">                       epochs=args.epochs,</span><br><span class="line">                       name=args.name,</span><br><span class="line">                       test_freq=args.val_freq,</span><br><span class="line">                       device=args.device)</span><br><span class="line"><span class="comment"># train</span></span><br><span class="line">best_model = trainer.train()</span><br></pre></td></tr></table></figure>

<h4 id="4-model-trainer-py"><a href="#4-model-trainer-py" class="headerlink" title="4.model_trainer.py"></a>4.model_trainer.py</h4><p>​    其实这就没啥好说的了，无非就是训练（算loss，反向传播，画图，训练日志，保存模型）和测试（计算均值和方差）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ModelTrainer</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, *kwargs</span>):</span></span><br><span class="line">  		<span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">self</span>):</span></span><br><span class="line">        best_tloss = <span class="number">1e8</span></span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(self.epochs + <span class="number">1</span>):</span><br><span class="line">            sys.stdout.flush()</span><br><span class="line">            loss = self.train_epoch(epoch)</span><br><span class="line">            self.losses.append(loss)</span><br><span class="line">            self.writer.add_scalar(<span class="string">&#x27;Loss/train&#x27;</span>, loss, epoch)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> epoch % self.test_freq == <span class="number">0</span>:</span><br><span class="line">                tloss = self.test_epoch(epoch)</span><br><span class="line">                self.tlosses.append(tloss)</span><br><span class="line">                self.plot_losses()</span><br><span class="line">                self.writer.add_scalar(<span class="string">&#x27;Loss/validation&#x27;</span>, tloss, epoch)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> tloss &lt; best_tloss:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&#x27;saving model.&#x27;</span>)</span><br><span class="line">                    net_fname = os.path.join(self.wts_dir, <span class="built_in">str</span>(self.name) + <span class="string">&#x27;.net&#x27;</span>)</span><br><span class="line">                    torch.save(self.model.state_dict(), net_fname)	<span class="comment"># 把表现更好的模型存到本地</span></span><br><span class="line">                    best_tloss = tloss</span><br><span class="line"></span><br><span class="line">            self.scheduler.step()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Visualize gradients</span></span><br><span class="line">            total_norm = <span class="number">0.</span></span><br><span class="line">            nan_count = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> tag, parm <span class="keyword">in</span> self.model.named_parameters():</span><br><span class="line">                <span class="keyword">if</span> torch.isnan(parm.grad).<span class="built_in">any</span>():</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&quot;Encountered NaNs in gradients at &#123;&#125; layer&quot;</span>.<span class="built_in">format</span>(tag))</span><br><span class="line">                    nan_count += <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    self.writer.add_histogram(tag, parm.grad.data.cpu().numpy(), epoch)</span><br><span class="line">                    param_norm = parm.grad.data.norm(<span class="number">2</span>)</span><br><span class="line">                    total_norm += param_norm.item() ** <span class="number">2</span></span><br><span class="line"></span><br><span class="line">            total_norm = total_norm ** (<span class="number">1.</span> / <span class="number">2</span>)</span><br><span class="line">            self.writer.add_scalar(<span class="string">&#x27;Gradient/2-norm&#x27;</span>, total_norm, epoch)</span><br><span class="line">            <span class="keyword">if</span> nan_count &gt; <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">&quot;Encountered NaNs in gradients&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># plot losses one more time</span></span><br><span class="line">        self.plot_losses()</span><br><span class="line">        <span class="comment"># re-load the best state dictionary that was saved earlier.</span></span><br><span class="line">        self.model.load_state_dict(torch.load(net_fname, map_location=<span class="string">&#x27;cpu&#x27;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># export scalar data to JSON for external processing</span></span><br><span class="line">        self.writer.export_scalars_to_json(<span class="string">&quot;./all_scalars.json&quot;</span>)</span><br><span class="line">        self.writer.close()</span><br><span class="line">        <span class="keyword">return</span> self.model</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train_epoch</span>(<span class="params">self, epoch</span>):</span></span><br><span class="line">        start = time.time()</span><br><span class="line">        running_loss = <span class="number">0</span></span><br><span class="line">        batches_per_dataset = <span class="built_in">len</span>(self.trainloader.dataset) / self.trainloader.batch_size</span><br><span class="line">        self.model.train()  <span class="comment"># Put model in training mode</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i, X <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.trainloader):</span><br><span class="line">            self.optimizer.zero_grad()</span><br><span class="line">            depth, labels = X[<span class="string">&#x27;depth&#x27;</span>].to(self.device), \</span><br><span class="line">                            X[<span class="string">&#x27;label&#x27;</span>].to(self.device)</span><br><span class="line"></span><br><span class="line">            y_pred = self.model(depth)</span><br><span class="line">            loss = self.criterion(y_pred, labels)</span><br><span class="line">            <span class="keyword">if</span> loss.data == -<span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>):</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;inf loss caught, not backpropping&#x27;</span>)</span><br><span class="line">                running_loss += -<span class="number">1000</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                loss.backward()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.</span></span><br><span class="line">                torch.nn.utils.clip_grad_norm_(self.model.parameters(), <span class="number">10.</span>)</span><br><span class="line"></span><br><span class="line">                self.optimizer.step()</span><br><span class="line">                running_loss += loss.item()</span><br><span class="line"></span><br><span class="line">        stop = time.time()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Epoch %s -  Train  Loss: %.5f Time: %.5f&#x27;</span> % (<span class="built_in">str</span>(epoch).zfill(<span class="number">3</span>),</span><br><span class="line">                                                            running_loss / batches_per_dataset,</span><br><span class="line">                                                            stop - start))</span><br><span class="line">        <span class="keyword">return</span> running_loss / batches_per_dataset</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_epoch</span>(<span class="params">self, epoch</span>):</span></span><br><span class="line">        start = time.time()</span><br><span class="line">        running_loss = <span class="number">0</span></span><br><span class="line">        batches_per_dataset = <span class="built_in">len</span>(self.testloader.dataset) / self.testloader.batch_size</span><br><span class="line">        self.model.<span class="built_in">eval</span>()  <span class="comment"># Put batch norm layers in eval mode</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            <span class="keyword">for</span> i, X <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.testloader):</span><br><span class="line">                depth, labels = X[<span class="string">&#x27;depth&#x27;</span>].to(self.device), \</span><br><span class="line">                                X[<span class="string">&#x27;label&#x27;</span>].to(self.device)</span><br><span class="line">                y_pred = self.model(depth)</span><br><span class="line">                loss = self.criterion(y_pred, labels)</span><br><span class="line">                running_loss += loss.item()</span><br><span class="line"></span><br><span class="line">        stop = time.time()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Epoch %s -  Test  Loss: %.5f Euc. Time: %.5f&#x27;</span> % (<span class="built_in">str</span>(epoch).zfill(<span class="number">3</span>),</span><br><span class="line">                                                                running_loss / batches_per_dataset,</span><br><span class="line">                                                                stop - start))</span><br><span class="line">        <span class="keyword">return</span> running_loss / batches_per_dataset</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_best_model</span>(<span class="params">self, best_model, fname_suffix=<span class="string">&#x27;&#x27;</span>, dual_quat_mode=<span class="literal">False</span></span>):</span></span><br><span class="line">        best_model.<span class="built_in">eval</span>()  <span class="comment"># Put model in evaluation mode</span></span><br><span class="line">		...</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            <span class="keyword">for</span> X <span class="keyword">in</span> self.testloader:</span><br><span class="line">                depth, all_labels, labels = X[<span class="string">&#x27;depth&#x27;</span>].to(self.device), \</span><br><span class="line">                                            X[<span class="string">&#x27;all_labels&#x27;</span>].to(self.device), \</span><br><span class="line">                                            X[<span class="string">&#x27;label&#x27;</span>].to(self.device)</span><br><span class="line">                y_pred = best_model(depth, all_labels)</span><br><span class="line">                y_pred = y_pred.view(y_pred.size(<span class="number">0</span>), -<span class="number">1</span>, <span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> dual_quat_mode:</span><br><span class="line">                    y_pred = dual_quaternion_to_screw_batch_mode(y_pred)</span><br><span class="line">                    labels = dual_quaternion_to_screw_batch_mode(labels)</span><br><span class="line"></span><br><span class="line">                err = labels - y_pred</span><br><span class="line">                all_l_hat_err = torch.cat(</span><br><span class="line">                    (all_l_hat_err, torch.mean(torch.norm(err[:, :, :<span class="number">3</span>], dim=-<span class="number">1</span>), dim=-<span class="number">1</span>).cpu()))</span><br><span class="line">                all_m_err = torch.cat((all_m_err, torch.mean(torch.norm(err[:, :, <span class="number">3</span>:<span class="number">6</span>], dim=-<span class="number">1</span>), dim=-<span class="number">1</span>).cpu()))</span><br><span class="line">                all_q_err = torch.cat((all_q_err, torch.mean(err[:, :, <span class="number">6</span>], dim=-<span class="number">1</span>).cpu()))</span><br><span class="line">                all_d_err = torch.cat((all_d_err, torch.mean(err[:, :, <span class="number">7</span>], dim=-<span class="number">1</span>).cpu()))</span><br><span class="line"></span><br><span class="line">                all_l_hat_std = torch.cat(</span><br><span class="line">                    (all_l_hat_std, torch.std(torch.norm(err[:, :, :<span class="number">3</span>], dim=-<span class="number">1</span>), dim=-<span class="number">1</span>).cpu()))</span><br><span class="line">                all_m_std = torch.cat((all_m_std, torch.std(torch.norm(err[:, :, <span class="number">3</span>:<span class="number">6</span>], dim=-<span class="number">1</span>), dim=-<span class="number">1</span>).cpu()))</span><br><span class="line">                all_q_std = torch.cat((all_q_std, torch.std(err[:, :, <span class="number">6</span>], dim=-<span class="number">1</span>).cpu()))</span><br><span class="line">                all_d_std = torch.cat((all_d_std, torch.std(err[:, :, <span class="number">7</span>], dim=-<span class="number">1</span>).cpu()))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Plot variation of screw axis</span></span><br><span class="line">		<span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">plot_grad_flow</span>(<span class="params">self, named_parameters</span>):</span></span><br><span class="line">		<span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">plot_losses</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<h4 id="5-Other-Modules"><a href="#5-Other-Modules" class="headerlink" title="5.Other Modules"></a>5.Other Modules</h4><p>​    其他辅助模组就暂时不继续占据篇幅了。注意到还存在一个noisy_models.py，引用了<a target="_blank" rel="noopener" href="https://github.com/babbatem/GeneralizingKinematics">这个仓库</a>，可能是对应的paper的数据增强手段，此处不表。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>(ICRA2021)ScrewNet</p><p><a href="https://kami-code.com/2021/12/20/screwnet/">https://kami-code.com/2021/12/20/screwnet/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Kami-code</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2021-12-20</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2022-02-14</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/ICRA/">ICRA</a><a class="link-muted mr-2" rel="tag" href="/tags/ScrewNet/">ScrewNet</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2021/12/22/pointnet-and-related-works/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">PointNet and related works</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2021/12/18/SE3353-assignment10/"><span class="level-item">SE3353-assignment10</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="SOHUCS" sid="2021/12/20/screwnet/"></div><script charset="utf-8" src="https://changyan.sohu.com/upload/changyan.js"></script><script>window.changyan.api.config({appid: 'cyvI88c19',conf: 'prod_634561f1ec380218934dcf2c12b8b70b'});</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.jpg" alt="Chen Bao"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Chen Bao</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shanghai, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">27</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">0</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">37</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Kami-code" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Kami-code"><i class="fab fa-github"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><!--!--><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-02-20T14:35:48.000Z">2022-02-20</time></p><p class="title"><a href="/2022/02/20/A-SDF/">(ICCV2021)A-SDF</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-02-17T03:10:18.000Z">2022-02-17</time></p><p class="title"><a href="/2022/02/17/behavior-clone/">(IJCAI2018)Behavior Clone from Observation</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-02-14T10:48:00.000Z">2022-02-14</time></p><p class="title"><a href="/2022/02/14/soil/">(IROS2021)SOIL</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-01-29T03:41:38.000Z">2022-01-29</time></p><p class="title"><a href="/2022/01/29/unigrasp/">(ICRA2020)Unigrasp</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-01-26T10:59:39.000Z">2022-01-26</time></p><p class="title"><a href="/2022/01/26/GIGA/">(RSS2021)GIGA</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2022/02/"><span class="level-start"><span class="level-item">February 2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/01/"><span class="level-start"><span class="level-item">January 2022</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/12/"><span class="level-start"><span class="level-item">December 2021</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/11/"><span class="level-start"><span class="level-item">November 2021</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/10/"><span class="level-start"><span class="level-item">October 2021</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/BCO/"><span class="tag">BCO</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CHOMP/"><span class="tag">CHOMP</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CVPR/"><span class="tag">CVPR</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Camera/"><span class="tag">Camera</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker/"><span class="tag">Docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GraspNet/"><span class="tag">GraspNet</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ICCV/"><span class="tag">ICCV</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ICRA/"><span class="tag">ICRA</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/IJCAI/"><span class="tag">IJCAI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/IROS/"><span class="tag">IROS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MongoDB/"><span class="tag">MongoDB</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MySQL/"><span class="tag">MySQL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Neo4j/"><span class="tag">Neo4j</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OpenCV/"><span class="tag">OpenCV</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OpenGL/"><span class="tag">OpenGL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PointNet/"><span class="tag">PointNet</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PointNet/"><span class="tag">PointNet++</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pybind11/"><span class="tag">Pybind11</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pybullet/"><span class="tag">Pybullet</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ROS/"><span class="tag">ROS</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RSS/"><span class="tag">RSS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SE3353/"><span class="tag">SE3353</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SOIL/"><span class="tag">SOIL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ScrewNet/"><span class="tag">ScrewNet</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Search/"><span class="tag">Search</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VoteNet/"><span class="tag">VoteNet</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/WebService/"><span class="tag">WebService</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/behavior-tree/"><span class="tag">behavior tree</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/compliers/"><span class="tag">compliers</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/deeplearning/"><span class="tag">deeplearning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ikfast/"><span class="tag">ikfast</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/lab/"><span class="tag">lab</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/mmdection/"><span class="tag">mmdection</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/moveit/"><span class="tag">moveit</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/planning/"><span class="tag">planning</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pybullet/"><span class="tag">pybullet</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/segmentation/"><span class="tag">segmentation</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Ryan &#039;s website" height="28"></a><span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span><span class="post-meta-divider">|</span><span id="busuanzi_container_site_uv" style="display:none">本站访客数<span id="busuanzi_value_site_uv"></span>人</span><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><p class="is-size-7"><span>&copy; 2022 Kami-code</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>